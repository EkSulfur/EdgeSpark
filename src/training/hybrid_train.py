"""
EdgeSpark æ··åˆæ–¹æ³•è®­ç»ƒè„šæœ¬
"""
import torch
import torch.nn as nn
import torch.optim as optim
import os
import time
import json
import argparse
from datetime import datetime
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
import numpy as np
import sys

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from hybrid_approach.hybrid_network import HybridEdgeMatchingNet
from simplified_approach.dataset_simple import create_simple_dataloaders

class HybridTrainer:
    """æ··åˆæ–¹æ³•è®­ç»ƒå™¨"""
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        self.save_dir = config['save_dir']
        os.makedirs(self.save_dir, exist_ok=True)
        
        # åˆ›å»ºæ¨¡å‹
        self.model = HybridEdgeMatchingNet(**config['model']).to(self.device)
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=config['training']['learning_rate'],
            weight_decay=config['training']['weight_decay']
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = optim.lr_scheduler.StepLR(
            self.optimizer,
            step_size=config['training']['step_size'],
            gamma=config['training']['gamma']
        )
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.BCEWithLogitsLoss()
        
        # å†å²è®°å½•
        self.history = []
        
        # æœ€ä½³ç»“æœè·Ÿè¸ª
        self.best_acc = 0.0
        self.best_epoch = 0
        
    def train_epoch(self, loader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        all_preds = []
        all_labels = []
        
        epoch_start = time.time()
        
        for batch_idx, batch in enumerate(loader):
            batch_start = time.time()
            
            points1 = batch['source_points'].to(self.device)
            points2 = batch['target_points'].to(self.device)
            labels = batch['label'].to(self.device)
            
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            logits = self.model(points1, points2)
            loss = self.criterion(logits, labels)
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            probs = torch.sigmoid(logits)
            preds = (probs > 0.5).float()
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            batch_time = time.time() - batch_start
            
            if batch_idx % 10 == 0:
                print(f'    Batch {batch_idx:3d}/{len(loader):3d} | '
                      f'Loss: {loss.item():.4f} | '
                      f'Time: {batch_time:.2f}s')
        
        avg_loss = total_loss / len(loader)
        acc = accuracy_score(all_labels, all_preds)
        
        epoch_time = time.time() - epoch_start
        print(f'    Epochè®­ç»ƒç”¨æ—¶: {epoch_time:.1f}s')
        
        return avg_loss, acc
    
    def validate_epoch(self, loader):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        all_preds = []
        all_probs = []
        all_labels = []
        
        with torch.no_grad():
            for batch in loader:
                points1 = batch['source_points'].to(self.device)
                points2 = batch['target_points'].to(self.device)
                labels = batch['label'].to(self.device)
                
                logits = self.model(points1, points2)
                loss = self.criterion(logits, labels)
                
                total_loss += loss.item()
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                
                all_preds.extend(preds.cpu().numpy())
                all_probs.extend(probs.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        avg_loss = total_loss / len(loader)
        acc = accuracy_score(all_labels, all_preds)
        
        try:
            precision, recall, f1, _ = precision_recall_fscore_support(
                all_labels, all_preds, average='binary', zero_division=0
            )
            auc = roc_auc_score(all_labels, all_probs)
        except:
            precision, recall, f1, auc = 0.0, 0.0, 0.0, 0.5
        
        return avg_loss, acc, precision, recall, f1, auc
    
    def train(self, train_loader, val_loader, epochs):
        """è®­ç»ƒå¾ªç¯"""
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒæ··åˆæ–¹æ³•")
        print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"é‡‡æ ·æ¬¡æ•°: {self.config['model']['num_samples']}")
        print(f"é‡‡æ ·æ–¹æ³•: {self.config['model']['sample_method']}")
        print(f"é›†æˆæ–¹æ³•: {self.config['model']['ensemble_method']}")
        
        start_time = time.time()
        
        for epoch in range(epochs):
            print(f"\nğŸ“Š Epoch {epoch+1}/{epochs}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader)
            
            # éªŒè¯
            val_loss, val_acc, val_precision, val_recall, val_f1, val_auc = self.validate_epoch(val_loader)
            
            # å­¦ä¹ ç‡æ›´æ–°
            self.scheduler.step()
            
            # è®°å½•
            self.history.append({
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'train_acc': train_acc,
                'val_loss': val_loss,
                'val_acc': val_acc,
                'val_f1': val_f1,
                'val_auc': val_auc,
                'lr': self.optimizer.param_groups[0]['lr']
            })
            
            # æ˜¾ç¤ºç»“æœ
            print(f"ğŸ“ˆ è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.4f}")
            print(f"ğŸ“Š éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.4f}, F1={val_f1:.4f}, AUC={val_auc:.4f}")
            print(f"ğŸ“š å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > self.best_acc:
                self.best_acc = val_acc
                self.best_epoch = epoch + 1
                print(f"  ğŸ’¾ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {self.best_acc:.4f}")
                
                # ä¿å­˜æ¨¡å‹
                torch.save({
                    'model_state_dict': self.model.state_dict(),
                    'optimizer_state_dict': self.optimizer.state_dict(),
                    'config': self.config,
                    'epoch': epoch + 1,
                    'best_acc': self.best_acc,
                    'history': self.history
                }, os.path.join(self.save_dir, 'best_hybrid_model.pth'))
            
            # æ—©åœæ£€æŸ¥
            if epoch - self.best_epoch + 1 >= self.config['training']['early_stopping']:
                print(f"ğŸ”´ æ—©åœ: {self.config['training']['early_stopping']} epochsæ— æå‡")
                break
        
        total_time = time.time() - start_time
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {total_time/60:.1f}åˆ†é’Ÿ")
        print(f"ğŸ† æœ€ä½³å‡†ç¡®ç‡: {self.best_acc:.4f} (epoch {self.best_epoch})")
        
        # ä¿å­˜è®­ç»ƒå†å²
        with open(os.path.join(self.save_dir, 'training_history.json'), 'w') as f:
            json.dump(self.history, f, indent=2)
        
        return self.best_acc, self.history

def create_hybrid_configs():
    """åˆ›å»ºä¸åŒçš„æ··åˆé…ç½®è¿›è¡Œå®éªŒ"""
    base_config = {
        'model': {
            'max_points': 1000,
            'num_samples': 5,
            'sample_method': 'diversified',
            'ensemble_method': 'weighted_average'
        },
        'training': {
            'learning_rate': 0.001,
            'weight_decay': 1e-4,
            'step_size': 10,
            'gamma': 0.5,
            'early_stopping': 8
        },
        'data': {
            'batch_size': 16,  # å‡å°‘batch sizeåº”å¯¹è®¡ç®—å¼€é”€
            'max_points': 1000,
            'num_workers': 4
        }
    }
    
    # å®éªŒé…ç½®
    configs = []
    
    # å®éªŒ1: ä¸åŒé‡‡æ ·æ¬¡æ•°
    for num_samples in [3, 5, 7]:
        config = base_config.copy()
        config['model'] = base_config['model'].copy()
        config['model']['num_samples'] = num_samples
        config['name'] = f'hybrid_samples_{num_samples}'
        config['save_dir'] = f'hybrid_experiments/samples_{num_samples}_{datetime.now().strftime("%m%d_%H%M")}'
        configs.append(config)
    
    # å®éªŒ2: ä¸åŒé›†æˆæ–¹æ³•
    for ensemble_method in ['simple_average', 'weighted_average', 'confidence_weighted']:
        config = base_config.copy()
        config['model'] = base_config['model'].copy()
        config['model']['ensemble_method'] = ensemble_method
        config['name'] = f'hybrid_ensemble_{ensemble_method}'
        config['save_dir'] = f'hybrid_experiments/ensemble_{ensemble_method}_{datetime.now().strftime("%m%d_%H%M")}'
        configs.append(config)
    
    # å®éªŒ3: ä¸åŒé‡‡æ ·æ–¹æ³•
    for sample_method in ['diversified', 'random']:
        config = base_config.copy()
        config['model'] = base_config['model'].copy()
        config['model']['sample_method'] = sample_method
        config['name'] = f'hybrid_sample_{sample_method}'
        config['save_dir'] = f'hybrid_experiments/sample_{sample_method}_{datetime.now().strftime("%m%d_%H%M")}'
        configs.append(config)
    
    return configs

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='EdgeSparkæ··åˆæ–¹æ³•è®­ç»ƒ')
    parser.add_argument('--experiment', type=str, default='all', 
                       help='å®éªŒç±»å‹: all, samples, ensemble, sample_method')
    parser.add_argument('--epochs', type=int, default=20, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼')
    args = parser.parse_args()
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ“š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader, val_loader, test_loader = create_simple_dataloaders(
        "dataset/train_set.pkl",
        "dataset/valid_set.pkl",
        "dataset/test_set.pkl",
        batch_size=16,
        max_points=1000,
        num_workers=4
    )
    
    # è·å–é…ç½®
    configs = create_hybrid_configs()
    
    # æ ¹æ®å®éªŒç±»å‹é€‰æ‹©é…ç½®
    if args.experiment == 'samples':
        configs = [c for c in configs if 'samples_' in c['name']]
    elif args.experiment == 'ensemble':
        configs = [c for c in configs if 'ensemble_' in c['name']]
    elif args.experiment == 'sample_method':
        configs = [c for c in configs if 'sample_' in c['name']]
    
    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick:
        configs = configs[:1]
        args.epochs = 5
        print("ğŸ”¥ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    
    # è¿è¡Œå®éªŒ
    results = []
    
    for i, config in enumerate(configs):
        print(f"\n{'='*60}")
        print(f"ğŸ§ª å®éªŒ {i+1}/{len(configs)}: {config['name']}")
        print(f"{'='*60}")
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = HybridTrainer(config)
        
        # å¼€å§‹è®­ç»ƒ
        best_acc, history = trainer.train(train_loader, val_loader, args.epochs)
        
        # è®°å½•ç»“æœ
        results.append({
            'name': config['name'],
            'config': config,
            'best_acc': best_acc,
            'final_epoch': len(history)
        })
        
        print(f"âœ… å®éªŒå®Œæˆ: {config['name']}, æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
    
    # æ€»ç»“ç»“æœ
    print(f"\n{'='*60}")
    print("ğŸ“Š å®éªŒæ€»ç»“")
    print(f"{'='*60}")
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    results.sort(key=lambda x: x['best_acc'], reverse=True)
    
    for i, result in enumerate(results):
        print(f"{i+1}. {result['name']}: {result['best_acc']:.4f}")
    
    # ä¿å­˜æ€»ç»“
    summary_path = f'hybrid_experiments/summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    os.makedirs(os.path.dirname(summary_path), exist_ok=True)
    with open(summary_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {summary_path}")
    
    # æ˜¾ç¤ºæœ€ä½³ç»“æœ
    if results:
        best_result = results[0]
        print(f"\nğŸ† æœ€ä½³ç»“æœ:")
        print(f"   å®éªŒ: {best_result['name']}")
        print(f"   å‡†ç¡®ç‡: {best_result['best_acc']:.4f}")
        print(f"   é…ç½®: {best_result['config']['model']}")
        
        # ä¸baselineæ¯”è¾ƒ
        baseline_acc = 0.6095  # final_approachçš„å‡†ç¡®ç‡
        improvement = best_result['best_acc'] - baseline_acc
        print(f"\nğŸ“ˆ ç›¸å¯¹äºbaseline ({baseline_acc:.4f}):")
        if improvement > 0:
            print(f"   æå‡: +{improvement:.4f} ({improvement/baseline_acc*100:.1f}%)")
        else:
            print(f"   ä¸‹é™: {improvement:.4f} ({improvement/baseline_acc*100:.1f}%)")

if __name__ == "__main__":
    main()