"""
åŸºäºPairingNetçš„EdgeSpark DataLoaderæ”¹è¿›ç‰ˆ
å¼•å…¥é‚»æ¥çŸ©é˜µã€ç©ºé—´å…³ç³»å»ºæ¨¡ç­‰å…³é”®ç‰¹æ€§
"""
import torch
import torch.utils.data as data
import pickle
import numpy as np
from typing import Dict, List, Tuple, Optional
import random
from scipy.spatial.distance import cdist

class PairingInspiredDataset(data.Dataset):
    """
    åŸºäºPairingNetè®¾è®¡çš„EdgeSparkæ•°æ®é›†
    å…³é”®æ”¹è¿›ï¼š
    1. é‚»æ¥çŸ©é˜µæ„å»º
    2. ç©ºé—´å…³ç³»å»ºæ¨¡
    3. æ ‡å‡†åŒ–çš„ç‚¹äº‘å½’ä¸€åŒ–
    4. æ›´å¥½çš„æ•°æ®é¢„å¤„ç†
    """
    
    def __init__(self, pkl_path: str, max_points: int = 2000, augment: bool = True, 
                 adjacency_k: int = 8, use_spatial_features: bool = True):
        """
        åˆå§‹åŒ–æ•°æ®é›†
        Args:
            pkl_path: pickleæ–‡ä»¶è·¯å¾„
            max_points: æœ€å¤§ç‚¹æ•°é™åˆ¶
            augment: æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼º
            adjacency_k: é‚»æ¥çŸ©é˜µçš„kå€¼ï¼ˆé‚»æ¥åŠå¾„ï¼‰
            use_spatial_features: æ˜¯å¦ä½¿ç”¨ç©ºé—´ç‰¹å¾
        """
        self.pkl_path = pkl_path
        self.max_points = max_points
        self.augment = augment
        self.adjacency_k = adjacency_k
        self.use_spatial_features = use_spatial_features
        
        # åŠ è½½æ•°æ®
        with open(pkl_path, 'rb') as f:
            self.data = pickle.load(f)
        
        # è§£ææ•°æ®
        self.edge_points = self.data['full_pcd_all']  # è¾¹ç¼˜ç‚¹äº‘åˆ—è¡¨
        self.gt_pairs = self.data['GT_pairs']  # åŒ¹é…å¯¹
        self.source_indices = self.data['source_ind']  # æºç¢ç‰‡åŒ¹é…ç‚¹ç´¢å¼•
        self.target_indices = self.data['target_ind']  # ç›®æ ‡ç¢ç‰‡åŒ¹é…ç‚¹ç´¢å¼•
        
        # è®¡ç®—å›ºå®šçš„å½’ä¸€åŒ–å‚æ•°ï¼ˆå‚è€ƒPairingNetï¼‰
        self.height_max = 1319  # PairingNetä¸­çš„å›ºå®šå€¼
        
        # åˆ›å»ºæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬
        self.samples = self._create_samples()
        
        print(f"ğŸ“Š PairingNeté£æ ¼æ•°æ®é›†åŠ è½½å®Œæˆ: {len(self.samples)} ä¸ªæ ·æœ¬")
        print(f"   - æ­£æ ·æœ¬: {sum(1 for s in self.samples if s['label'] == 1)}")
        print(f"   - è´Ÿæ ·æœ¬: {sum(1 for s in self.samples if s['label'] == 0)}")
        print(f"   - é‚»æ¥çŸ©é˜µkå€¼: {adjacency_k}")
        print(f"   - ä½¿ç”¨ç©ºé—´ç‰¹å¾: {use_spatial_features}")
    
    def _create_samples(self) -> List[Dict]:
        """åˆ›å»ºè®­ç»ƒæ ·æœ¬ï¼ˆæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ï¼‰"""
        samples = []
        
        # 1. åˆ›å»ºæ­£æ ·æœ¬
        for i, (source_idx, target_idx) in enumerate(self.gt_pairs):
            samples.append({
                'source_idx': source_idx,
                'target_idx': target_idx,
                'label': 1,
                'source_match_points': self.source_indices[i],
                'target_match_points': self.target_indices[i]
            })
        
        # 2. åˆ›å»ºè´Ÿæ ·æœ¬ï¼ˆéšæœºé…å¯¹ï¼‰
        num_fragments = len(self.edge_points)
        num_negative = len(self.gt_pairs)  # è´Ÿæ ·æœ¬æ•°é‡ç­‰äºæ­£æ ·æœ¬æ•°é‡
        
        # åˆ›å»ºæ‰€æœ‰å¯èƒ½çš„é…å¯¹
        all_pairs = set()
        for i in range(num_fragments):
            for j in range(i + 1, num_fragments):
                all_pairs.add((i, j))
        
        # ç§»é™¤æ­£æ ·æœ¬å¯¹
        positive_pairs = set()
        for source_idx, target_idx in self.gt_pairs:
            pair = (min(source_idx, target_idx), max(source_idx, target_idx))
            positive_pairs.add(pair)
        
        negative_pairs = list(all_pairs - positive_pairs)
        
        # éšæœºé€‰æ‹©è´Ÿæ ·æœ¬
        if len(negative_pairs) > 0:
            selected_negative = random.sample(negative_pairs, min(num_negative, len(negative_pairs)))
            
            for source_idx, target_idx in selected_negative:
                samples.append({
                    'source_idx': source_idx,
                    'target_idx': target_idx,
                    'label': 0,
                    'source_match_points': None,
                    'target_match_points': None
                })
        
        return samples
    
    def get_adjacency_matrix(self, points: np.ndarray) -> torch.Tensor:
        """
        æ„å»ºé‚»æ¥çŸ©é˜µï¼ˆå‚è€ƒPairingNetçš„get_adjacent2å‡½æ•°ï¼‰
        Args:
            points: ç‚¹äº‘æ•°æ® (n, 2)
        Returns:
            adjacency_matrix: é‚»æ¥çŸ©é˜µ (max_points, max_points)
        """
        n = len(points)
        
        # åˆ›å»ºåŸºç¡€é‚»æ¥çŸ©é˜µ
        adjacent_matrix = np.eye(n)
        temp = np.eye(n)
        
        # æ·»åŠ ké‚»æ¥å…³ç³»
        for i in range(self.adjacency_k):
            adjacent_matrix += np.roll(temp, i + 1, axis=0)
            adjacent_matrix += np.roll(temp, -i - 1, axis=0)
        
        # æ‰©å±•åˆ°max_pointså¤§å°
        full_matrix = np.zeros((self.max_points, self.max_points))
        full_matrix[:n, :n] = adjacent_matrix
        
        return torch.from_numpy(full_matrix).float()
    
    def extract_spatial_features(self, points: np.ndarray) -> np.ndarray:
        """
        æå–ç©ºé—´ç‰¹å¾ï¼ˆæ›²ç‡ã€è§’åº¦ç­‰ï¼‰
        Args:
            points: ç‚¹äº‘æ•°æ® (n, 2)
        Returns:
            spatial_features: ç©ºé—´ç‰¹å¾ (n, feature_dim)
        """
        if len(points) < 3:
            return np.zeros((len(points), 4))
        
        features = []
        
        for i in range(len(points)):
            # è·å–é‚»è¿‘ç‚¹
            prev_idx = (i - 1) % len(points)
            next_idx = (i + 1) % len(points)
            
            curr_point = points[i]
            prev_point = points[prev_idx]
            next_point = points[next_idx]
            
            # è®¡ç®—å‘é‡
            vec1 = prev_point - curr_point
            vec2 = next_point - curr_point
            
            # è®¡ç®—è§’åº¦
            dot_product = np.dot(vec1, vec2)
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            
            if norm1 > 1e-6 and norm2 > 1e-6:
                cos_angle = np.clip(dot_product / (norm1 * norm2), -1, 1)
                angle = np.arccos(cos_angle)
            else:
                angle = 0
            
            # è®¡ç®—æ›²ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
            if norm1 > 1e-6 and norm2 > 1e-6:
                cross_product = np.cross(vec1, vec2)
                curvature = abs(cross_product) / (norm1 * norm2)
            else:
                curvature = 0
            
            # ç‰¹å¾å‘é‡ï¼š[è§’åº¦, æ›²ç‡, è·ç¦»1, è·ç¦»2]
            features.append([angle, curvature, norm1, norm2])
        
        return np.array(features)
    
    def normalize_points_pairing_style(self, points: np.ndarray) -> np.ndarray:
        """
        æŒ‰ç…§PairingNeté£æ ¼å½’ä¸€åŒ–ç‚¹äº‘
        Args:
            points: åŸå§‹ç‚¹äº‘ (n, 2)
        Returns:
            normalized_points: å½’ä¸€åŒ–åçš„ç‚¹äº‘ (n, 2)
        """
        if len(points) == 0:
            return points
        
        # PairingNeté£æ ¼çš„å½’ä¸€åŒ–ï¼š/ (height_max / 2.) - 1
        normalized = points / (self.height_max / 2.0) - 1.0
        
        return normalized
    
    def pad_or_sample_points(self, points: np.ndarray) -> np.ndarray:
        """
        å¤„ç†ç‚¹äº‘é•¿åº¦ï¼ˆä¿æŒæœ‰åºæ€§ï¼‰
        Args:
            points: ç‚¹äº‘æ•°æ® (n, 2)
        Returns:
            processed_points: å¤„ç†åçš„ç‚¹äº‘ (max_points, 2)
        """
        if len(points) >= self.max_points:
            # ç­‰é—´éš”é‡‡æ ·ï¼Œä¿æŒè¾¹ç¼˜ç‚¹çš„ç©ºé—´è¿ç»­æ€§
            step = len(points) / self.max_points
            indices = np.round(np.arange(0, len(points), step)[:self.max_points]).astype(int)
            indices = np.clip(indices, 0, len(points) - 1)
            return points[indices]
        else:
            # ç”¨æœ€åä¸€ä¸ªç‚¹å¡«å……ï¼ˆé¿å…ç ´åç©ºé—´è¿ç»­æ€§ï¼‰
            padding = np.tile(points[-1:], (self.max_points - len(points), 1))
            return np.vstack([points, padding])
    
    def augment_points(self, points: np.ndarray) -> np.ndarray:
        """
        æ•°æ®å¢å¼ºï¼šæ—‹è½¬ã€å¹³ç§»ã€å™ªå£°
        Args:
            points: ç‚¹äº‘æ•°æ® (n, 2)
        Returns:
            augmented_points: å¢å¼ºåçš„ç‚¹äº‘ (n, 2)
        """
        if not self.augment or len(points) == 0:
            return points
        
        # éšæœºæ—‹è½¬
        if random.random() < 0.5:
            angle = random.uniform(-np.pi/12, np.pi/12)  # Â±15åº¦
            cos_a, sin_a = np.cos(angle), np.sin(angle)
            rotation_matrix = np.array([[cos_a, -sin_a], [sin_a, cos_a]])
            points = points @ rotation_matrix.T
        
        # éšæœºå¹³ç§»
        if random.random() < 0.3:
            shift = np.random.uniform(-0.05, 0.05, 2)
            points = points + shift
        
        # æ·»åŠ å™ªå£°
        if random.random() < 0.3:
            noise = np.random.normal(0, 0.005, points.shape)
            points = points + noise
        
        return points
    
    def __len__(self) -> int:
        return len(self.samples)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        """è·å–å•ä¸ªæ ·æœ¬"""
        sample = self.samples[idx]
        
        # è·å–è¾¹ç¼˜ç‚¹äº‘
        source_points = self.edge_points[sample['source_idx']].copy()
        target_points = self.edge_points[sample['target_idx']].copy()
        
        # æ•°æ®å¢å¼º
        source_points = self.augment_points(source_points)
        target_points = self.augment_points(target_points)
        
        # PairingNeté£æ ¼å½’ä¸€åŒ–
        source_points = self.normalize_points_pairing_style(source_points)
        target_points = self.normalize_points_pairing_style(target_points)
        
        # è®°å½•åŸå§‹é•¿åº¦
        source_length = len(source_points)
        target_length = len(target_points)
        
        # å¤„ç†ç‚¹äº‘é•¿åº¦
        source_points = self.pad_or_sample_points(source_points)
        target_points = self.pad_or_sample_points(target_points)
        
        # æ„å»ºé‚»æ¥çŸ©é˜µ
        source_adj = self.get_adjacency_matrix(source_points[:source_length])
        target_adj = self.get_adjacency_matrix(target_points[:target_length])
        
        result = {
            'source_points': torch.FloatTensor(source_points),
            'target_points': torch.FloatTensor(target_points),
            'source_adj': source_adj,
            'target_adj': target_adj,
            'source_length': torch.LongTensor([source_length]),
            'target_length': torch.LongTensor([target_length]),
            'label': torch.FloatTensor([sample['label']]),
            'source_idx': sample['source_idx'],
            'target_idx': sample['target_idx']
        }
        
        # æ·»åŠ ç©ºé—´ç‰¹å¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.use_spatial_features:
            source_spatial = self.extract_spatial_features(source_points[:source_length])
            target_spatial = self.extract_spatial_features(target_points[:target_length])
            
            # å¡«å……ç©ºé—´ç‰¹å¾
            if len(source_spatial) < self.max_points:
                padding = np.zeros((self.max_points - len(source_spatial), source_spatial.shape[1]))
                source_spatial = np.vstack([source_spatial, padding])
            
            if len(target_spatial) < self.max_points:
                padding = np.zeros((self.max_points - len(target_spatial), target_spatial.shape[1]))
                target_spatial = np.vstack([target_spatial, padding])
            
            result['source_spatial'] = torch.FloatTensor(source_spatial)
            result['target_spatial'] = torch.FloatTensor(target_spatial)
        
        return result

def create_pairing_inspired_dataloaders(
    train_pkl: str, 
    valid_pkl: str, 
    test_pkl: str,
    batch_size: int = 32,
    max_points: int = 2000,
    num_workers: int = 4,
    adjacency_k: int = 8,
    use_spatial_features: bool = True
) -> Tuple[data.DataLoader, data.DataLoader, data.DataLoader]:
    """
    åˆ›å»ºåŸºäºPairingNetçš„æ•°æ®åŠ è½½å™¨
    """
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = PairingInspiredDataset(
        train_pkl, 
        max_points=max_points, 
        augment=True, 
        adjacency_k=adjacency_k,
        use_spatial_features=use_spatial_features
    )
    
    valid_dataset = PairingInspiredDataset(
        valid_pkl, 
        max_points=max_points, 
        augment=False, 
        adjacency_k=adjacency_k,
        use_spatial_features=use_spatial_features
    )
    
    test_dataset = PairingInspiredDataset(
        test_pkl, 
        max_points=max_points, 
        augment=False, 
        adjacency_k=adjacency_k,
        use_spatial_features=use_spatial_features
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = data.DataLoader(
        train_dataset, 
        batch_size=batch_size, 
        shuffle=True, 
        num_workers=num_workers,
        pin_memory=True
    )
    
    valid_loader = data.DataLoader(
        valid_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True
    )
    
    test_loader = data.DataLoader(
        test_dataset, 
        batch_size=batch_size, 
        shuffle=False, 
        num_workers=num_workers,
        pin_memory=True
    )
    
    return train_loader, valid_loader, test_loader

# æµ‹è¯•å‡½æ•°
def test_pairing_inspired_dataloader():
    """æµ‹è¯•æ–°çš„æ•°æ®åŠ è½½å™¨"""
    print("ğŸ” æµ‹è¯•PairingNeté£æ ¼çš„æ•°æ®åŠ è½½å™¨...")
    
    try:
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader, valid_loader, test_loader = create_pairing_inspired_dataloaders(
            "dataset/train_set.pkl",
            "dataset/valid_set.pkl",
            "dataset/test_set.pkl",
            batch_size=4,
            max_points=1000,
            num_workers=0,
            adjacency_k=8,
            use_spatial_features=True
        )
        
        # æµ‹è¯•ä¸€ä¸ªæ‰¹æ¬¡
        for batch_idx, batch in enumerate(train_loader):
            print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}:")
            print(f"   - source_points: {batch['source_points'].shape}")
            print(f"   - target_points: {batch['target_points'].shape}")
            print(f"   - source_adj: {batch['source_adj'].shape}")
            print(f"   - target_adj: {batch['target_adj'].shape}")
            print(f"   - source_length: {batch['source_length']}")
            print(f"   - target_length: {batch['target_length']}")
            print(f"   - label: {batch['label']}")
            
            if 'source_spatial' in batch:
                print(f"   - source_spatial: {batch['source_spatial'].shape}")
                print(f"   - target_spatial: {batch['target_spatial'].shape}")
            
            # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
            break
        
        print("\nâœ… æ•°æ®åŠ è½½å™¨æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_pairing_inspired_dataloader()