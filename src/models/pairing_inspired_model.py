"""
åŸºäºPairingNetçš„EdgeSparkæ¨¡å‹æ”¹è¿›ç‰ˆ
å……åˆ†åˆ©ç”¨é‚»æ¥çŸ©é˜µå’Œç©ºé—´ç‰¹å¾è¿›è¡Œç¢ç‰‡åŒ¹é…
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
from typing import Dict, Optional, Tuple

class GraphConvLayer(nn.Module):
    """
    å›¾å·ç§¯å±‚ - åŸºäºPairingNetçš„GCNè®¾è®¡
    """
    def __init__(self, in_features: int, out_features: int, dropout: float = 0.1):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        
        # çº¿æ€§å˜æ¢
        self.linear = nn.Linear(in_features, out_features)
        self.dropout = nn.Dropout(dropout)
        self.batch_norm = nn.BatchNorm1d(out_features)
        self.activation = nn.ReLU()
        
    def forward(self, x: torch.Tensor, adj: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            x: èŠ‚ç‚¹ç‰¹å¾ (batch_size, num_nodes, in_features)
            adj: é‚»æ¥çŸ©é˜µ (batch_size, num_nodes, num_nodes)
        Returns:
            output: è¾“å‡ºç‰¹å¾ (batch_size, num_nodes, out_features)
        """
        # çº¿æ€§å˜æ¢
        x = self.linear(x)  # (batch_size, num_nodes, out_features)
        
        # å›¾å·ç§¯ï¼šé‚»æ¥çŸ©é˜µä¸ç‰¹å¾çš„çŸ©é˜µä¹˜æ³•
        x = torch.bmm(adj, x)  # (batch_size, num_nodes, out_features)
        
        # æ‰¹å½’ä¸€åŒ–ï¼ˆéœ€è¦è°ƒæ•´ç»´åº¦ï¼‰
        batch_size, num_nodes, features = x.shape
        x = x.view(-1, features)  # (batch_size * num_nodes, features)
        x = self.batch_norm(x)
        x = x.view(batch_size, num_nodes, features)
        
        # æ¿€æ´»å’Œdropout
        x = self.activation(x)
        x = self.dropout(x)
        
        return x

class MultiScaleGCN(nn.Module):
    """
    å¤šå°ºåº¦å›¾å·ç§¯ç½‘ç»œ
    """
    def __init__(self, input_dim: int, hidden_dims: list, dropout: float = 0.1):
        super().__init__()
        self.layers = nn.ModuleList()
        
        # æ„å»ºå¤šå±‚GCN
        dims = [input_dim] + hidden_dims
        for i in range(len(dims) - 1):
            self.layers.append(GraphConvLayer(dims[i], dims[i+1], dropout))
        
        # è·³è·ƒè¿æ¥çš„æŠ•å½±å±‚
        self.skip_projections = nn.ModuleList()
        for hidden_dim in hidden_dims:
            self.skip_projections.append(nn.Linear(input_dim, hidden_dim))
    
    def forward(self, x: torch.Tensor, adj: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            x: è¾“å…¥ç‰¹å¾ (batch_size, num_nodes, input_dim)
            adj: é‚»æ¥çŸ©é˜µ (batch_size, num_nodes, num_nodes)
        Returns:
            output: è¾“å‡ºç‰¹å¾ (batch_size, num_nodes, hidden_dims[-1])
        """
        original_x = x
        
        for i, layer in enumerate(self.layers):
            x = layer(x, adj)
            
            # è·³è·ƒè¿æ¥
            if i < len(self.skip_projections):
                skip = self.skip_projections[i](original_x)
                x = x + skip
        
        return x

class SpatialAttention(nn.Module):
    """
    ç©ºé—´æ³¨æ„åŠ›æœºåˆ¶
    """
    def __init__(self, feature_dim: int, spatial_dim: int = 4):
        super().__init__()
        self.feature_dim = feature_dim
        self.spatial_dim = spatial_dim
        
        # æ³¨æ„åŠ›è®¡ç®—
        self.attention = nn.Sequential(
            nn.Linear(feature_dim + spatial_dim, feature_dim),
            nn.ReLU(),
            nn.Linear(feature_dim, 1),
            nn.Sigmoid()
        )
        
    def forward(self, features: torch.Tensor, spatial: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            features: ç‰¹å¾ (batch_size, num_nodes, feature_dim)
            spatial: ç©ºé—´ç‰¹å¾ (batch_size, num_nodes, spatial_dim)
        Returns:
            attended_features: æ³¨æ„åŠ›åŠ æƒåçš„ç‰¹å¾ (batch_size, num_nodes, feature_dim)
        """
        # æ‹¼æ¥ç‰¹å¾å’Œç©ºé—´ä¿¡æ¯
        combined = torch.cat([features, spatial], dim=-1)
        
        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        attention_weights = self.attention(combined)  # (batch_size, num_nodes, 1)
        
        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
        attended_features = features * attention_weights
        
        return attended_features

class PairingInspiredEncoder(nn.Module):
    """
    åŸºäºPairingNetçš„ç¼–ç å™¨
    """
    def __init__(self, max_points: int = 1000, use_spatial: bool = True):
        super().__init__()
        self.max_points = max_points
        self.use_spatial = use_spatial
        
        # è¾“å…¥ç»´åº¦ï¼š2Dåæ ‡ + å¯é€‰çš„ç©ºé—´ç‰¹å¾
        input_dim = 2
        if use_spatial:
            input_dim += 4  # è§’åº¦ã€æ›²ç‡ã€è·ç¦»1ã€è·ç¦»2
        
        # å¤šå°ºåº¦GCN
        self.gcn = MultiScaleGCN(
            input_dim=input_dim,
            hidden_dims=[64, 128, 256, 128],
            dropout=0.1
        )
        
        # ç©ºé—´æ³¨æ„åŠ›
        if use_spatial:
            self.spatial_attention = SpatialAttention(128, 4)
        
        # å…¨å±€æ± åŒ–
        self.global_pool = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten()
        )
        
        # æœ€ç»ˆæŠ•å½±
        self.final_projection = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 64)
        )
        
    def forward(self, points: torch.Tensor, adj: torch.Tensor, 
                spatial: Optional[torch.Tensor] = None, 
                length: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            points: ç‚¹äº‘åæ ‡ (batch_size, num_points, 2)
            adj: é‚»æ¥çŸ©é˜µ (batch_size, num_points, num_points)
            spatial: ç©ºé—´ç‰¹å¾ (batch_size, num_points, 4)
            length: å®é™…ç‚¹äº‘é•¿åº¦ (batch_size, 1)
        Returns:
            features: å…¨å±€ç‰¹å¾ (batch_size, 64)
        """
        # å‡†å¤‡è¾“å…¥ç‰¹å¾
        if self.use_spatial and spatial is not None:
            x = torch.cat([points, spatial], dim=-1)
        else:
            x = points
        
        # å¤šå°ºåº¦GCN
        x = self.gcn(x, adj)  # (batch_size, num_points, 128)
        
        # ç©ºé—´æ³¨æ„åŠ›
        if self.use_spatial and spatial is not None:
            x = self.spatial_attention(x, spatial)
        
        # å¤„ç†å˜é•¿åºåˆ—ï¼ˆä½¿ç”¨maskï¼‰
        if length is not None:
            # åˆ›å»ºmask
            batch_size, max_len = x.shape[0], x.shape[1]
            mask = torch.arange(max_len, device=x.device).expand(batch_size, max_len)
            mask = mask < length  # (batch_size, max_len)
            
            # åº”ç”¨mask
            x = x * mask.unsqueeze(-1).float()
        
        # å…¨å±€æ± åŒ–
        x = x.transpose(1, 2)  # (batch_size, 128, num_points)
        x = self.global_pool(x)  # (batch_size, 128)
        
        # æœ€ç»ˆæŠ•å½±
        x = self.final_projection(x)  # (batch_size, 64)
        
        return x

class FocalLoss(nn.Module):
    """
    FocalLosså®ç°
    """
    def __init__(self, alpha: float = 0.55, gamma: float = 2.0):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            inputs: é¢„æµ‹logits (batch_size, 1)
            targets: çœŸå®æ ‡ç­¾ (batch_size, 1)
        Returns:
            loss: focal loss
        """
        bce_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')
        p_t = torch.exp(-bce_loss)
        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
        focal_weight = alpha_t * (1 - p_t) ** self.gamma
        focal_loss = focal_weight * bce_loss
        
        return focal_loss.mean()

class PairingInspiredMatchingNet(nn.Module):
    """
    åŸºäºPairingNetçš„åŒ¹é…ç½‘ç»œ
    """
    def __init__(self, max_points: int = 1000, use_spatial: bool = True, temperature: float = 1.0):
        super().__init__()
        self.max_points = max_points
        self.use_spatial = use_spatial
        self.temperature = temperature
        
        # ç¼–ç å™¨
        self.encoder = PairingInspiredEncoder(max_points, use_spatial)
        
        # åŒ¹é…ç½‘ç»œ
        self.matching_net = nn.Sequential(
            nn.Linear(64 * 3 + 1, 128),  # 64*2 + 64 + 1 (æ‹¼æ¥+å·®å€¼+ç›¸ä¼¼åº¦)
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 1)
        )
        
    def compute_temperature_similarity(self, feat1: torch.Tensor, feat2: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—æ¸©åº¦ç¼©æ”¾çš„ç›¸ä¼¼åº¦
        Args:
            feat1: ç‰¹å¾1 (batch_size, 64)
            feat2: ç‰¹å¾2 (batch_size, 64)
        Returns:
            similarity: æ¸©åº¦ç¼©æ”¾åçš„ç›¸ä¼¼åº¦ (batch_size, 1)
        """
        # L2å½’ä¸€åŒ–
        feat1_norm = F.normalize(feat1, p=2, dim=1)
        feat2_norm = F.normalize(feat2, p=2, dim=1)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        cos_sim = torch.sum(feat1_norm * feat2_norm, dim=1, keepdim=True)
        
        # æ¸©åº¦ç¼©æ”¾
        scaled_sim = cos_sim / self.temperature
        
        return scaled_sim
    
    def forward(self, batch: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            batch: æ‰¹æ¬¡æ•°æ®
        Returns:
            logits: åŒ¹é…é¢„æµ‹ (batch_size, 1)
        """
        # æå–è¾“å…¥
        source_points = batch['source_points']
        target_points = batch['target_points']
        source_adj = batch['source_adj']
        target_adj = batch['target_adj']
        source_length = batch['source_length']
        target_length = batch['target_length']
        
        source_spatial = batch.get('source_spatial', None)
        target_spatial = batch.get('target_spatial', None)
        
        # ç¼–ç 
        source_feat = self.encoder(source_points, source_adj, source_spatial, source_length)
        target_feat = self.encoder(target_points, target_adj, target_spatial, target_length)
        
        # ç‰¹å¾ç»„åˆ
        diff_feat = source_feat - target_feat  # å·®å€¼ç‰¹å¾
        temp_sim = self.compute_temperature_similarity(source_feat, target_feat)  # æ¸©åº¦ç›¸ä¼¼åº¦
        
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        combined_feat = torch.cat([source_feat, target_feat, diff_feat, temp_sim], dim=1)
        
        # åŒ¹é…é¢„æµ‹
        logits = self.matching_net(combined_feat)
        
        return logits

class PairingInspiredTrainer:
    """
    åŸºäºPairingNetçš„è®­ç»ƒå™¨
    """
    def __init__(self, max_points: int = 1000, use_spatial: bool = True, 
                 temperature: float = 1.0, alpha: float = 0.55, gamma: float = 2.0):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆ›å»ºæ¨¡å‹
        self.model = PairingInspiredMatchingNet(
            max_points=max_points,
            use_spatial=use_spatial,
            temperature=temperature
        ).to(self.device)
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, weight_decay=1e-4)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=15, gamma=0.5)
        
        # æŸå¤±å‡½æ•°
        self.criterion = FocalLoss(alpha=alpha, gamma=gamma)
        
        # å†å²è®°å½•
        self.history = []
        
        print(f"ğŸš€ PairingNeté£æ ¼è®­ç»ƒå™¨åˆå§‹åŒ–:")
        print(f"   - æœ€å¤§ç‚¹æ•°: {max_points}")
        print(f"   - ä½¿ç”¨ç©ºé—´ç‰¹å¾: {use_spatial}")
        print(f"   - æ¸©åº¦å‚æ•°: {temperature}")
        print(f"   - FocalLoss: Î±={alpha}, Î³={gamma}")
        print(f"   - æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
        
    def train_epoch(self, loader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, batch in enumerate(loader):
            # ç§»åŠ¨åˆ°è®¾å¤‡
            for key in batch:
                if isinstance(batch[key], torch.Tensor):
                    batch[key] = batch[key].to(self.device)
            
            labels = batch['label']
            
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            logits = self.model(batch)
            loss = self.criterion(logits, labels)
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            probs = torch.sigmoid(logits)
            preds = (probs > 0.5).float()
            correct += (preds == labels).sum().item()
            total += labels.size(0)
            
            if batch_idx % 50 == 0:
                print(f'    Batch {batch_idx:3d}/{len(loader):3d} | Loss: {loss.item():.4f} | Acc: {correct/total:.4f}')
        
        avg_loss = total_loss / len(loader)
        accuracy = correct / total
        
        return avg_loss, accuracy
    
    def validate_epoch(self, loader):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total = 0
        
        with torch.no_grad():
            for batch in loader:
                # ç§»åŠ¨åˆ°è®¾å¤‡
                for key in batch:
                    if isinstance(batch[key], torch.Tensor):
                        batch[key] = batch[key].to(self.device)
                
                labels = batch['label']
                
                logits = self.model(batch)
                loss = self.criterion(logits, labels)
                
                total_loss += loss.item()
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                correct += (preds == labels).sum().item()
                total += labels.size(0)
        
        avg_loss = total_loss / len(loader)
        accuracy = correct / total
        
        return avg_loss, accuracy
    
    def train(self, train_loader, val_loader, epochs: int = 30):
        """è®­ç»ƒä¸»å¾ªç¯"""
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒ PairingNeté£æ ¼æ¨¡å‹...")
        
        best_acc = 0.0
        
        for epoch in range(epochs):
            print(f"\nğŸ“Š Epoch {epoch+1}/{epochs}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader)
            
            # éªŒè¯
            val_loss, val_acc = self.validate_epoch(val_loader)
            
            # å­¦ä¹ ç‡æ›´æ–°
            self.scheduler.step()
            
            # è®°å½•å†å²
            self.history.append({
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'train_acc': train_acc,
                'val_loss': val_loss,
                'val_acc': val_acc,
                'lr': self.optimizer.param_groups[0]['lr']
            })
            
            # æ˜¾ç¤ºç»“æœ
            print(f"ğŸ“ˆ è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.4f}")
            print(f"ğŸ“Š éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.4f}")
            print(f"ğŸ“š å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                print(f"  ğŸ’¾ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
                torch.save(self.model.state_dict(), 'best_pairing_inspired_model.pth')
            
            # æå‰åœæ­¢
            if epoch >= 10 and val_acc < 0.55:
                print("ğŸ”´ éªŒè¯å‡†ç¡®ç‡è¿‡ä½ï¼Œæå‰åœæ­¢")
                break
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
        return best_acc

# æµ‹è¯•å‡½æ•°
def test_pairing_inspired_model():
    """æµ‹è¯•æ¨¡å‹"""
    print("ğŸ” æµ‹è¯•PairingNeté£æ ¼æ¨¡å‹...")
    
    try:
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        import sys
        import os
        sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'data'))
        from pairing_inspired_dataloader import create_pairing_inspired_dataloaders
        
        train_loader, val_loader, test_loader = create_pairing_inspired_dataloaders(
            "dataset/train_set.pkl",
            "dataset/valid_set.pkl",
            "dataset/test_set.pkl",
            batch_size=8,
            max_points=1000,
            num_workers=0,
            use_spatial_features=True
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = PairingInspiredTrainer(
            max_points=1000,
            use_spatial=True,
            temperature=1.0,
            alpha=0.55,
            gamma=2.0
        )
        
        # æµ‹è¯•ä¸€ä¸ªå‰å‘ä¼ æ’­
        for batch in train_loader:
            # ç§»åŠ¨åˆ°è®¾å¤‡
            for key in batch:
                if isinstance(batch[key], torch.Tensor):
                    batch[key] = batch[key].to(trainer.device)
            
            logits = trainer.model(batch)
            print(f"âœ… æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {logits.shape}")
            print(f"   - æ ·æœ¬æ ‡ç­¾: {batch['label'].squeeze()}")
            print(f"   - é¢„æµ‹æ¦‚ç‡: {torch.sigmoid(logits).squeeze()}")
            break
        
        print("âœ… æ¨¡å‹æµ‹è¯•é€šè¿‡!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_pairing_inspired_model()