"""
å¿«é€Ÿæµ‹è¯•å¢å¼ºç‰¹å¾æå–å™¨çš„æ•ˆæœ
"""

import torch
import torch.nn as nn
import numpy as np
import os
import sys
from sklearn.metrics import accuracy_score
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'data'))
from improved_dataset_loader import create_improved_dataloaders
from enhanced_feature_extractor import EnhancedFragmentMatcher, MultiScaleFeatureExtractor

def test_feature_separability():
    """æµ‹è¯•ç‰¹å¾å¯åˆ†ç¦»æ€§"""
    print("ğŸ” å¿«é€Ÿæµ‹è¯•å¢å¼ºç‰¹å¾æå–å™¨")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå°batchï¼‰
    print("ğŸ“š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader, val_loader, test_loader = create_improved_dataloaders(
        "dataset/train_set.pkl",
        "dataset/valid_set.pkl",
        "dataset/test_set.pkl",
        batch_size=32,
        max_points=1000,
        num_workers=0,
        sampling_strategy='ordered'
    )
    
    # åˆ›å»ºæ¨¡å‹
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ“± ä½¿ç”¨è®¾å¤‡: {device}")
    
    # æµ‹è¯•å¢å¼ºç‰¹å¾æå–å™¨
    enhanced_model = EnhancedFragmentMatcher(max_points=1000).to(device)
    
    # æµ‹è¯•åŸå§‹ç‰¹å¾æå–å™¨ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
    simple_extractor = MultiScaleFeatureExtractor(max_points=1000).to(device)
    
    print(f"ğŸ“Š å¢å¼ºæ¨¡å‹å‚æ•°: {sum(p.numel() for p in enhanced_model.parameters()):,}")
    
    # ä»éªŒè¯é›†æå–ç‰¹å¾
    enhanced_features1 = []
    enhanced_features2 = []
    simple_features1 = []
    simple_features2 = []
    labels = []
    
    enhanced_model.eval()
    simple_extractor.eval()
    
    with torch.no_grad():
        for i, batch in enumerate(val_loader):
            if i >= 5:  # åªæµ‹è¯•å‰5ä¸ªbatch
                break
                
            points1 = batch['source_points'].to(device)
            points2 = batch['target_points'].to(device)
            batch_labels = batch['label'].to(device)
            
            # å¢å¼ºç‰¹å¾æå–
            _, feat1_enhanced, feat2_enhanced = enhanced_model(points1, points2)
            
            # ç®€å•ç‰¹å¾æå–
            feat1_simple = simple_extractor(points1)
            feat2_simple = simple_extractor(points2)
            
            enhanced_features1.extend(feat1_enhanced.cpu().numpy())
            enhanced_features2.extend(feat2_enhanced.cpu().numpy())
            simple_features1.extend(feat1_simple.cpu().numpy())
            simple_features2.extend(feat2_simple.cpu().numpy())
            labels.extend(batch_labels.cpu().numpy())
            
            print(f"  å¤„ç†äº† {i+1}/5 ä¸ªbatch")
    
    # è½¬æ¢ä¸ºnumpy
    enhanced_features1 = np.array(enhanced_features1)
    enhanced_features2 = np.array(enhanced_features2)
    simple_features1 = np.array(simple_features1)
    simple_features2 = np.array(simple_features2)
    labels = np.array(labels).flatten()
    
    print(f"ğŸ“ˆ æå–äº† {len(labels)} ä¸ªæ ·æœ¬çš„ç‰¹å¾")
    print(f"   æ­£æ ·æœ¬: {np.sum(labels == 1)}")
    print(f"   è´Ÿæ ·æœ¬: {np.sum(labels == 0)}")
    
    # è®¡ç®—ç‰¹å¾å¯åˆ†ç¦»æ€§
    def compute_separability(feat1, feat2, labels):
        """è®¡ç®—ç‰¹å¾å¯åˆ†ç¦»æ€§"""
        combined = np.concatenate([feat1, feat2], axis=1)
        
        pos_features = combined[labels == 1]
        neg_features = combined[labels == 0]
        
        if len(pos_features) < 2 or len(neg_features) < 2:
            return 0.0
        
        # ç±»é—´è·ç¦»
        pos_center = np.mean(pos_features, axis=0)
        neg_center = np.mean(neg_features, axis=0)
        inter_dist = np.linalg.norm(pos_center - neg_center)
        
        # ç±»å†…è·ç¦»
        pos_distances = [np.linalg.norm(f - pos_center) for f in pos_features]
        neg_distances = [np.linalg.norm(f - neg_center) for f in neg_features]
        intra_dist = (np.mean(pos_distances) + np.mean(neg_distances)) / 2
        
        return inter_dist / (intra_dist + 1e-8)
    
    # è®¡ç®—å¯åˆ†ç¦»æ€§
    enhanced_separability = compute_separability(enhanced_features1, enhanced_features2, labels)
    simple_separability = compute_separability(simple_features1, simple_features2, labels)
    
    print(f"\nğŸ“Š ç‰¹å¾å¯åˆ†ç¦»æ€§å¯¹æ¯”:")
    print(f"   å¢å¼ºç‰¹å¾æå–å™¨: {enhanced_separability:.4f}")
    print(f"   ç®€å•ç‰¹å¾æå–å™¨: {simple_separability:.4f}")
    print(f"   æ”¹è¿›å€æ•°: {enhanced_separability / (simple_separability + 1e-8):.2f}x")
    
    # å¯è§†åŒ–ç‰¹å¾ç©ºé—´
    def visualize_features(feat1, feat2, labels, title, save_name):
        """å¯è§†åŒ–ç‰¹å¾ç©ºé—´"""
        combined = np.concatenate([feat1, feat2], axis=1)
        
        # ä½¿ç”¨PCAé™ç»´ï¼ˆæ›´å¿«ï¼‰
        from sklearn.decomposition import PCA
        pca = PCA(n_components=2)
        features_2d = pca.fit_transform(combined)
        
        plt.figure(figsize=(10, 8))
        colors = ['red' if label == 0 else 'blue' for label in labels]
        plt.scatter(features_2d[:, 0], features_2d[:, 1], c=colors, alpha=0.6)
        plt.title(f'{title} (å¯åˆ†ç¦»æ€§: {compute_separability(feat1, feat2, labels):.4f})')
        plt.xlabel('PCA Component 1')
        plt.ylabel('PCA Component 2')
        plt.legend(['Non-matching', 'Matching'])
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(f'{save_name}.png', dpi=150, bbox_inches='tight')
        plt.close()
        print(f"   ä¿å­˜å¯è§†åŒ–å›¾: {save_name}.png")
    
    print(f"\nğŸ“ˆ ç”Ÿæˆç‰¹å¾ç©ºé—´å¯è§†åŒ–...")
    visualize_features(enhanced_features1, enhanced_features2, labels, 
                      "å¢å¼ºç‰¹å¾æå–å™¨", "enhanced_features")
    visualize_features(simple_features1, simple_features2, labels, 
                      "ç®€å•ç‰¹å¾æå–å™¨", "simple_features")
    
    # æµ‹è¯•å„ä¸ªå‡ ä½•ç‰¹å¾çš„è´¡çŒ®
    print(f"\nğŸ” åˆ†æå‡ ä½•ç‰¹å¾è´¡çŒ®...")
    
    from enhanced_feature_extractor import GeometricFeatureExtractor
    geo_extractor = GeometricFeatureExtractor()
    
    # ä»æ•°æ®é›†æå–å‡ ä½•ç‰¹å¾
    dataset = val_loader.dataset
    geometric_separabilities = {}
    
    for feature_type in ['curvature', 'angle', 'fourier', 'moment', 'distance']:
        type_features1 = []
        type_features2 = []
        
        for i in range(min(100, len(dataset))):  # æµ‹è¯•100ä¸ªæ ·æœ¬
            sample = dataset.samples[i]
            source_points = dataset.edge_points[sample['source_idx']]
            target_points = dataset.edge_points[sample['target_idx']]
            
            # å»é™¤padding
            source_valid = source_points[~((source_points == -999).all(axis=1))]
            target_valid = target_points[~((target_points == -999).all(axis=1))]
            
            if len(source_valid) > 3 and len(target_valid) > 3:
                source_geo = geo_extractor.extract_all_features(source_valid)
                target_geo = geo_extractor.extract_all_features(target_valid)
                
                type_features1.append(source_geo[feature_type])
                type_features2.append(target_geo[feature_type])
        
        if len(type_features1) > 10:
            type_features1 = np.array(type_features1)
            type_features2 = np.array(type_features2)
            type_labels = np.array([dataset.samples[i]['label'] for i in range(len(type_features1))])
            
            separability = compute_separability(type_features1, type_features2, type_labels)
            geometric_separabilities[feature_type] = separability
            
            print(f"   {feature_type:>8}: {separability:.4f}")
    
    # ç»“æœæ€»ç»“
    print(f"\n" + "=" * 50)
    print("ğŸ“Š æ€»ç»“")
    print("=" * 50)
    
    if enhanced_separability > simple_separability * 1.5:
        print("ğŸ‰ å¢å¼ºç‰¹å¾æå–å™¨æ˜¾è‘—æ”¹å–„äº†ç‰¹å¾å¯åˆ†ç¦»æ€§ï¼")
        print("ğŸ’¡ å‡ ä½•ç‰¹å¾å·¥ç¨‹æ˜¯æœ‰æ•ˆçš„")
    elif enhanced_separability > simple_separability * 1.1:
        print("âœ… å¢å¼ºç‰¹å¾æå–å™¨æœ‰ä¸€å®šæ”¹å–„")
        print("ğŸ’¡ è¿˜æœ‰è¿›ä¸€æ­¥ä¼˜åŒ–ç©ºé—´")
    else:
        print("âš ï¸  å¢å¼ºç‰¹å¾æå–å™¨æ”¹å–„æœ‰é™")
        print("ğŸ’¡ éœ€è¦é‡æ–°æ€è€ƒç‰¹å¾å·¥ç¨‹ç­–ç•¥")
    
    # æ‰¾åˆ°æœ€æœ‰æ•ˆçš„å‡ ä½•ç‰¹å¾
    if geometric_separabilities:
        best_geo_feature = max(geometric_separabilities.items(), key=lambda x: x[1])
        print(f"ğŸ† æœ€æœ‰æ•ˆçš„å‡ ä½•ç‰¹å¾: {best_geo_feature[0]} (å¯åˆ†ç¦»æ€§: {best_geo_feature[1]:.4f})")
    
    return {
        'enhanced_separability': enhanced_separability,
        'simple_separability': simple_separability,
        'geometric_separabilities': geometric_separabilities,
        'improvement_ratio': enhanced_separability / (simple_separability + 1e-8)
    }

if __name__ == "__main__":
    results = test_feature_separability()
    print(f"\nğŸ¯ æœ€ç»ˆç»“æœ: {results}")