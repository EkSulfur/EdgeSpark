"""
å¢å¼ºçš„å‡ ä½•ç‰¹å¾æå–å™¨
ä¸“é—¨è®¾è®¡ç”¨äºè§£å†³ç‰¹å¾å¯åˆ†ç¦»æ€§ä¸è¶³çš„é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
from typing import List, Dict, Tuple
from scipy.spatial.distance import cdist

class GeometricFeatureExtractor:
    """å‡ ä½•ç‰¹å¾æå–å™¨"""
    
    def __init__(self):
        self.eps = 1e-8
    
    def extract_curvature_features(self, points: np.ndarray, window_size: int = 5) -> np.ndarray:
        """
        æå–æ›²ç‡ç‰¹å¾
        Args:
            points: (N, 2) è¾¹ç¼˜ç‚¹åæ ‡
            window_size: è®¡ç®—æ›²ç‡çš„çª—å£å¤§å°
        Returns:
            curvature_features: æ›²ç‡ç›¸å…³ç‰¹å¾
        """
        if len(points) < window_size:
            return np.zeros(6)
        
        # è®¡ç®—å±€éƒ¨æ›²ç‡
        curvatures = []
        for i in range(len(points)):
            # è·å–å±€éƒ¨çª—å£
            indices = [(i + j - window_size//2) % len(points) for j in range(window_size)]
            local_points = points[indices]
            
            # æ‹Ÿåˆåœ†å¼§è®¡ç®—æ›²ç‡
            if len(local_points) >= 3:
                curvature = self._compute_local_curvature(local_points)
                curvatures.append(curvature)
        
        curvatures = np.array(curvatures)
        
        # æ›²ç‡ç»Ÿè®¡ç‰¹å¾
        features = [
            np.mean(curvatures),           # å¹³å‡æ›²ç‡
            np.std(curvatures),            # æ›²ç‡æ ‡å‡†å·®
            np.max(curvatures),            # æœ€å¤§æ›²ç‡
            np.min(curvatures),            # æœ€å°æ›²ç‡
            np.sum(curvatures > np.median(curvatures)) / len(curvatures),  # é«˜æ›²ç‡æ¯”ä¾‹
            np.sum(np.abs(np.diff(curvatures)))  # æ›²ç‡å˜åŒ–æ€»é‡
        ]
        
        return np.array(features)
    
    def _compute_local_curvature(self, points: np.ndarray) -> float:
        """è®¡ç®—å±€éƒ¨æ›²ç‡ï¼ˆä½¿ç”¨ä¸‰ç‚¹æ³•ï¼‰"""
        if len(points) < 3:
            return 0.0
        
        # é€‰æ‹©ä¸‰ä¸ªç‚¹
        p1, p2, p3 = points[0], points[len(points)//2], points[-1]
        
        # è®¡ç®—ä¸‰è§’å½¢é¢ç§¯
        area = 0.5 * abs((p2[0] - p1[0]) * (p3[1] - p1[1]) - (p3[0] - p1[0]) * (p2[1] - p1[1]))
        
        # è®¡ç®—ä¸‰è¾¹é•¿åº¦
        a = np.linalg.norm(p2 - p3)
        b = np.linalg.norm(p1 - p3)
        c = np.linalg.norm(p1 - p2)
        
        # å¤–æ¥åœ†åŠå¾„
        if area < self.eps:
            return 0.0
        
        R = (a * b * c) / (4 * area + self.eps)
        
        # æ›²ç‡æ˜¯åŠå¾„çš„å€’æ•°
        return 1.0 / (R + self.eps)
    
    def extract_angle_features(self, points: np.ndarray) -> np.ndarray:
        """
        æå–è§’åº¦ç‰¹å¾
        Args:
            points: (N, 2) è¾¹ç¼˜ç‚¹åæ ‡
        Returns:
            angle_features: è§’åº¦ç›¸å…³ç‰¹å¾
        """
        if len(points) < 3:
            return np.zeros(8)
        
        # è®¡ç®—ç›¸é‚»çº¿æ®µè§’åº¦
        angles = []
        for i in range(len(points)):
            p1 = points[i-1]
            p2 = points[i]
            p3 = points[(i+1) % len(points)]
            
            # è®¡ç®—ä¸¤ä¸ªå‘é‡
            v1 = p2 - p1
            v2 = p3 - p2
            
            # è®¡ç®—è§’åº¦
            angle = self._compute_angle(v1, v2)
            angles.append(angle)
        
        angles = np.array(angles)
        
        # è§’åº¦ç»Ÿè®¡ç‰¹å¾
        features = [
            np.mean(angles),               # å¹³å‡è§’åº¦
            np.std(angles),                # è§’åº¦æ ‡å‡†å·®
            np.sum(angles < np.pi/2) / len(angles),  # é”è§’æ¯”ä¾‹
            np.sum(angles > 3*np.pi/2) / len(angles),  # å‡¹è§’æ¯”ä¾‹
            np.max(angles),                # æœ€å¤§è§’åº¦
            np.min(angles),                # æœ€å°è§’åº¦
            np.sum(np.abs(np.diff(angles))),  # è§’åº¦å˜åŒ–æ€»é‡
            len(self._find_corner_points(points, angles))  # è§’ç‚¹æ•°é‡
        ]
        
        return np.array(features)
    
    def _compute_angle(self, v1: np.ndarray, v2: np.ndarray) -> float:
        """è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„è§’åº¦"""
        len1 = np.linalg.norm(v1) + self.eps
        len2 = np.linalg.norm(v2) + self.eps
        
        cos_angle = np.dot(v1, v2) / (len1 * len2)
        cos_angle = np.clip(cos_angle, -1.0, 1.0)
        
        return np.arccos(cos_angle)
    
    def _find_corner_points(self, points: np.ndarray, angles: np.ndarray, threshold: float = np.pi/3) -> List[int]:
        """æ‰¾åˆ°è§’ç‚¹ï¼ˆè§’åº¦å˜åŒ–å¤§çš„ç‚¹ï¼‰"""
        corners = []
        for i, angle in enumerate(angles):
            if angle < threshold or angle > 2*np.pi - threshold:
                corners.append(i)
        return corners
    
    def extract_fourier_descriptors(self, points: np.ndarray, n_descriptors: int = 16) -> np.ndarray:
        """
        æå–å‚…é‡Œå¶æè¿°å­
        Args:
            points: (N, 2) è¾¹ç¼˜ç‚¹åæ ‡
            n_descriptors: å‚…é‡Œå¶æè¿°å­æ•°é‡
        Returns:
            fourier_features: å‚…é‡Œå¶æè¿°å­ç‰¹å¾
        """
        if len(points) < 4:
            return np.zeros(n_descriptors)
        
        # å°†ç‚¹è½¬æ¢ä¸ºå¤æ•°è¡¨ç¤º
        complex_points = points[:, 0] + 1j * points[:, 1]
        
        # è®¡ç®—å‚…é‡Œå¶å˜æ¢
        fft_coeffs = np.fft.fft(complex_points)
        
        # å½’ä¸€åŒ–ï¼ˆå¹³ç§»ä¸å˜æ€§ï¼‰
        if abs(fft_coeffs[0]) > self.eps:
            fft_coeffs = fft_coeffs / fft_coeffs[0]
        
        # æ—‹è½¬ä¸å˜æ€§ï¼ˆä½¿ç”¨å¹…å€¼ï¼‰
        magnitudes = np.abs(fft_coeffs)
        
        # å°ºåº¦ä¸å˜æ€§ï¼ˆå½’ä¸€åŒ–ï¼‰
        if magnitudes[1] > self.eps:
            magnitudes = magnitudes / magnitudes[1]
        
        # å–å‰n_descriptorsä¸ªæè¿°å­
        n_take = min(n_descriptors, len(magnitudes))
        descriptors = magnitudes[1:n_take+1]  # è·³è¿‡ç›´æµåˆ†é‡
        
        # å¦‚æœä¸å¤Ÿï¼Œç”¨é›¶å¡«å……
        if len(descriptors) < n_descriptors:
            descriptors = np.pad(descriptors, (0, n_descriptors - len(descriptors)))
        
        return descriptors
    
    def extract_geometric_moments(self, points: np.ndarray) -> np.ndarray:
        """
        æå–å‡ ä½•çŸ©ç‰¹å¾
        Args:
            points: (N, 2) è¾¹ç¼˜ç‚¹åæ ‡
        Returns:
            moment_features: å‡ ä½•çŸ©ç‰¹å¾
        """
        if len(points) < 3:
            return np.zeros(7)
        
        # è®¡ç®—è´¨å¿ƒ
        centroid = np.mean(points, axis=0)
        
        # ä¸­å¿ƒåŒ–
        centered_points = points - centroid
        
        # è®¡ç®—å„é˜¶çŸ©
        x, y = centered_points[:, 0], centered_points[:, 1]
        
        # äºŒé˜¶çŸ©
        m20 = np.mean(x**2)
        m02 = np.mean(y**2)
        m11 = np.mean(x * y)
        
        # è®¡ç®—ä¸»è½´æ–¹å‘
        if m20 != m02:
            theta = 0.5 * np.arctan(2 * m11 / (m20 - m02 + self.eps))
        else:
            theta = np.pi / 4 if m11 > 0 else -np.pi / 4
        
        # è®¡ç®—æ¤­åœ†å‚æ•°
        cos_theta, sin_theta = np.cos(theta), np.sin(theta)
        
        # ä¸»è½´ä¸Šçš„çŸ©
        mu20_prime = m20 * cos_theta**2 + m02 * sin_theta**2 + 2 * m11 * cos_theta * sin_theta
        mu02_prime = m20 * sin_theta**2 + m02 * cos_theta**2 - 2 * m11 * cos_theta * sin_theta
        
        # è®¡ç®—ç‰¹å¾
        features = [
            m20 + m02,                     # æ€»æƒ¯æ€§
            abs(m20 - m02),                # æƒ¯æ€§å·®
            abs(m11),                      # åæ–œåº¦
            theta,                         # ä¸»è½´è§’åº¦
            mu20_prime / (mu02_prime + self.eps),  # é•¿çŸ­è½´æ¯”
            np.sqrt(mu20_prime),           # ä¸»è½´é•¿åº¦
            np.sqrt(mu02_prime)            # æ¬¡è½´é•¿åº¦
        ]
        
        return np.array(features)
    
    def extract_distance_features(self, points: np.ndarray) -> np.ndarray:
        """
        æå–è·ç¦»ç‰¹å¾
        Args:
            points: (N, 2) è¾¹ç¼˜ç‚¹åæ ‡
        Returns:
            distance_features: è·ç¦»ç›¸å…³ç‰¹å¾
        """
        if len(points) < 2:
            return np.zeros(6)
        
        # è®¡ç®—è´¨å¿ƒ
        centroid = np.mean(points, axis=0)
        
        # åˆ°è´¨å¿ƒçš„è·ç¦»
        distances_to_centroid = np.linalg.norm(points - centroid, axis=1)
        
        # ç›¸é‚»ç‚¹è·ç¦»
        adjacent_distances = []
        for i in range(len(points)):
            dist = np.linalg.norm(points[i] - points[(i+1) % len(points)])
            adjacent_distances.append(dist)
        adjacent_distances = np.array(adjacent_distances)
        
        features = [
            np.mean(distances_to_centroid),     # å¹³å‡åŠå¾„
            np.std(distances_to_centroid),      # åŠå¾„æ ‡å‡†å·®
            np.max(distances_to_centroid),      # æœ€å¤§åŠå¾„
            np.mean(adjacent_distances),        # å¹³å‡è¾¹é•¿
            np.std(adjacent_distances),         # è¾¹é•¿æ ‡å‡†å·®
            np.max(adjacent_distances) / (np.mean(adjacent_distances) + self.eps)  # è¾¹é•¿å˜åŒ–åº¦
        ]
        
        return np.array(features)
    
    def extract_all_features(self, points: np.ndarray) -> Dict[str, np.ndarray]:
        """æå–æ‰€æœ‰å‡ ä½•ç‰¹å¾"""
        features = {
            'curvature': self.extract_curvature_features(points),
            'angle': self.extract_angle_features(points),
            'fourier': self.extract_fourier_descriptors(points),
            'moment': self.extract_geometric_moments(points),
            'distance': self.extract_distance_features(points)
        }
        
        return features

class MultiScaleFeatureExtractor(nn.Module):
    """å¤šå°ºåº¦ç‰¹å¾æå–å™¨"""
    
    def __init__(self, max_points: int = 1000):
        super().__init__()
        self.max_points = max_points
        self.geometric_extractor = GeometricFeatureExtractor()
        
        # å‡ ä½•ç‰¹å¾ç»´åº¦
        self.curvature_dim = 6
        self.angle_dim = 8
        self.fourier_dim = 16
        self.moment_dim = 7
        self.distance_dim = 6
        self.total_geometric_dim = self.curvature_dim + self.angle_dim + self.fourier_dim + self.moment_dim + self.distance_dim
        
        # åŸå§‹åæ ‡ç‰¹å¾æå–å™¨ï¼ˆä¿ç•™ä½†æ”¹è¿›ï¼‰
        self.coordinate_encoder = nn.Sequential(
            nn.Conv1d(2, 64, kernel_size=7, padding=3),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Conv1d(64, 128, kernel_size=5, padding=2),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Conv1d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(1)
        )
        
        # å‡ ä½•ç‰¹å¾ç¼–ç å™¨
        self.geometric_encoder = nn.Sequential(
            nn.Linear(self.total_geometric_dim, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 256)
        )
        
        # ç‰¹å¾èåˆå±‚
        self.feature_fusion = nn.Sequential(
            nn.Linear(256 + 256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128)
        )
        
        # ç‰¹å¾å½’ä¸€åŒ–
        self.feature_norm = nn.LayerNorm(128)
        
    def extract_geometric_features_batch(self, points_batch: torch.Tensor) -> torch.Tensor:
        """æ‰¹é‡æå–å‡ ä½•ç‰¹å¾"""
        batch_size = points_batch.shape[0]
        geometric_features = torch.zeros(batch_size, self.total_geometric_dim, device=points_batch.device)
        
        for i in range(batch_size):
            # è½¬æ¢ä¸ºnumpyè¿›è¡Œå‡ ä½•ç‰¹å¾æå–
            points_np = points_batch[i].cpu().numpy()
            
            # å»é™¤paddingï¼ˆå‡è®¾paddingå€¼ä¸º-999ï¼‰
            valid_mask = ~((points_np == -999).all(axis=1))
            if valid_mask.sum() > 0:
                valid_points = points_np[valid_mask]
                
                # æå–æ‰€æœ‰å‡ ä½•ç‰¹å¾
                features = self.geometric_extractor.extract_all_features(valid_points)
                
                # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
                feature_vector = np.concatenate([
                    features['curvature'],
                    features['angle'],
                    features['fourier'],
                    features['moment'],
                    features['distance']
                ])
                
                # å¤„ç†NaNå’ŒInf
                feature_vector = np.nan_to_num(feature_vector, nan=0.0, posinf=1.0, neginf=-1.0)
                
                geometric_features[i] = torch.FloatTensor(feature_vector).to(points_batch.device)
        
        return geometric_features
    
    def forward(self, points: torch.Tensor) -> torch.Tensor:
        """
        å‰å‘ä¼ æ’­
        Args:
            points: (batch_size, num_points, 2)
        Returns:
            features: (batch_size, 128)
        """
        batch_size = points.shape[0]
        
        # 1. æå–å‡ ä½•ç‰¹å¾
        geometric_features = self.extract_geometric_features_batch(points)
        
        # 2. æå–åæ ‡ç‰¹å¾
        coord_input = points.transpose(1, 2)  # (batch_size, 2, num_points)
        coordinate_features = self.coordinate_encoder(coord_input).squeeze(-1)  # (batch_size, 256)
        
        # 3. ç¼–ç å‡ ä½•ç‰¹å¾
        encoded_geometric = self.geometric_encoder(geometric_features)  # (batch_size, 256)
        
        # 4. ç‰¹å¾èåˆ
        combined_features = torch.cat([coordinate_features, encoded_geometric], dim=1)
        fused_features = self.feature_fusion(combined_features)  # (batch_size, 128)
        
        # 5. ç‰¹å¾å½’ä¸€åŒ–
        normalized_features = self.feature_norm(fused_features)
        
        return normalized_features

class ContrastiveLoss(nn.Module):
    """å¯¹æ¯”å­¦ä¹ æŸå¤±å‡½æ•°"""
    
    def __init__(self, margin: float = 1.0, temperature: float = 0.1):
        super().__init__()
        self.margin = margin
        self.temperature = temperature
        
    def forward(self, features1: torch.Tensor, features2: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—å¯¹æ¯”æŸå¤±
        Args:
            features1: (batch_size, feature_dim) ç¬¬ä¸€ç»„ç‰¹å¾
            features2: (batch_size, feature_dim) ç¬¬äºŒç»„ç‰¹å¾
            labels: (batch_size,) æ ‡ç­¾ (1è¡¨ç¤ºåŒ¹é…, 0è¡¨ç¤ºä¸åŒ¹é…)
        """
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        features1_norm = F.normalize(features1, p=2, dim=1)
        features2_norm = F.normalize(features2, p=2, dim=1)
        similarity = torch.sum(features1_norm * features2_norm, dim=1)
        
        # å¯¹æ¯”æŸå¤±
        positive_mask = labels.float()
        negative_mask = 1 - positive_mask
        
        # æ­£æ ·æœ¬æŸå¤±ï¼šæœ€å¤§åŒ–ç›¸ä¼¼åº¦
        positive_loss = positive_mask * (1 - similarity)
        
        # è´Ÿæ ·æœ¬æŸå¤±ï¼šæœ€å°åŒ–ç›¸ä¼¼åº¦ï¼ˆä½†æœ‰marginï¼‰
        negative_loss = negative_mask * torch.clamp(similarity - self.margin, min=0)
        
        loss = positive_loss + negative_loss
        
        return loss.mean()

class EnhancedFragmentMatcher(nn.Module):
    """å¢å¼ºçš„ç¢ç‰‡åŒ¹é…ç½‘ç»œ"""
    
    def __init__(self, max_points: int = 1000):
        super().__init__()
        self.max_points = max_points
        
        # ç‰¹å¾æå–å™¨
        self.feature_extractor = MultiScaleFeatureExtractor(max_points)
        
        # åŒ¹é…ç½‘ç»œ
        self.matcher = nn.Sequential(
            # è¾“å…¥ï¼šä¸¤ä¸ª128ç»´ç‰¹å¾ + å·®å€¼ + ç›¸ä¼¼åº¦
            nn.Linear(128 * 2 + 128 + 3, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.4),
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1)
        )
        
    def forward(self, points1: torch.Tensor, points2: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        Args:
            points1: (batch_size, num_points, 2)
            points2: (batch_size, num_points, 2)
        Returns:
            match_logits: (batch_size, 1) åŒ¹é…æ¦‚ç‡
            features1: (batch_size, 128) ç¬¬ä¸€ç»„ç‰¹å¾
            features2: (batch_size, 128) ç¬¬äºŒç»„ç‰¹å¾
        """
        # æå–ç‰¹å¾
        features1 = self.feature_extractor(points1)
        features2 = self.feature_extractor(points2)
        
        # è®¡ç®—ç‰¹å¾å…³ç³»
        diff = features1 - features2  # å·®å€¼ç‰¹å¾
        
        # å¤šç§ç›¸ä¼¼åº¦åº¦é‡
        cosine_sim = F.cosine_similarity(features1, features2, dim=1, eps=1e-8).unsqueeze(1)
        euclidean_dist = torch.norm(features1 - features2, p=2, dim=1, keepdim=True)
        dot_product = torch.sum(features1 * features2, dim=1, keepdim=True)
        
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        combined = torch.cat([
            features1, features2, diff, 
            cosine_sim, euclidean_dist, dot_product
        ], dim=1)
        
        # åŒ¹é…é¢„æµ‹
        match_logits = self.matcher(combined)
        
        return match_logits, features1, features2

def test_geometric_feature_extractor():
    """æµ‹è¯•å‡ ä½•ç‰¹å¾æå–å™¨"""
    print("ğŸ§ª æµ‹è¯•å‡ ä½•ç‰¹å¾æå–å™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    # åœ†å½¢
    t = np.linspace(0, 2*np.pi, 100)
    circle_points = np.column_stack([np.cos(t), np.sin(t)])
    
    # æ­£æ–¹å½¢
    square_points = np.array([
        [0, 0], [1, 0], [1, 1], [0, 1]
    ])
    
    extractor = GeometricFeatureExtractor()
    
    # æµ‹è¯•åœ†å½¢ç‰¹å¾
    print("\nåœ†å½¢ç‰¹å¾:")
    circle_features = extractor.extract_all_features(circle_points)
    for name, features in circle_features.items():
        print(f"  {name}: {features[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ªå€¼
    
    # æµ‹è¯•æ­£æ–¹å½¢ç‰¹å¾
    print("\næ­£æ–¹å½¢ç‰¹å¾:")
    square_features = extractor.extract_all_features(square_points)
    for name, features in square_features.items():
        print(f"  {name}: {features[:3]}...")
    
    print("âœ… å‡ ä½•ç‰¹å¾æå–å™¨æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_geometric_feature_extractor()