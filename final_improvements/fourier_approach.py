#!/usr/bin/env python3
"""
åŸºäºå‚…é‡Œå¶å˜æ¢çš„ç¢ç‰‡ç¼–ç æ–¹æ³•
ç”¨æˆ·æåˆ°çš„æ”¹è¿›æ€è·¯ï¼šåŸºäºå‚…é‡Œå¶å˜æ¢çš„ç¢ç‰‡ç¼–ç 
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
from typing import Tuple, List

class FourierShapeEncoder(nn.Module):
    """
    åŸºäºå‚…é‡Œå¶å˜æ¢çš„å½¢çŠ¶ç¼–ç å™¨
    å°†è¾¹ç¼˜è½®å»“è½¬æ¢ä¸ºé¢‘åŸŸç‰¹å¾
    """
    def __init__(self, max_points=1000, num_freqs=64, feature_dim=128):
        super().__init__()
        self.max_points = max_points
        self.num_freqs = num_freqs
        self.feature_dim = feature_dim
        
        # å‚…é‡Œå¶ç‰¹å¾å¤„ç†ç½‘ç»œ - ä¿®å¤ç»´åº¦é—®é¢˜
        self.fourier_net = nn.Sequential(
            nn.Linear(num_freqs * 2 - 1, 256),  # real + imaginary parts (å»æ‰ä¸€ä¸ªç›¸ä½)
            nn.ReLU(),
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, feature_dim)
        )
        
        # ç©ºé—´ç‰¹å¾ç¼–ç å™¨ï¼ˆä½œä¸ºè¡¥å……ï¼‰
        self.spatial_encoder = nn.Sequential(
            nn.Conv1d(2, 64, kernel_size=5, padding=2),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(1)
        )
        
        # ç‰¹å¾èåˆ
        self.fusion = nn.Sequential(
            nn.Linear(feature_dim + 128, feature_dim),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
    def extract_fourier_descriptors(self, points):
        """
        æå–å‚…é‡Œå¶æè¿°ç¬¦
        Args:
            points: (batch_size, num_points, 2)
        Returns:
            fourier_features: (batch_size, num_freqs * 2)
        """
        batch_size, num_points, _ = points.shape
        
        # è½¬æ¢ä¸ºå¤æ•°è¡¨ç¤º
        complex_points = points[:, :, 0] + 1j * points[:, :, 1]  # (batch_size, num_points)
        
        # åº”ç”¨FFT
        fft_result = torch.fft.fft(complex_points, dim=1)  # (batch_size, num_points)
        
        # å–å‰num_freqsä¸ªé¢‘ç‡åˆ†é‡
        if num_points > self.num_freqs:
            fft_result = fft_result[:, :self.num_freqs]
        else:
            # å¦‚æœç‚¹æ•°ä¸å¤Ÿï¼Œç”¨é›¶å¡«å……
            padding = torch.zeros(batch_size, self.num_freqs - num_points, 
                                device=fft_result.device, dtype=fft_result.dtype)
            fft_result = torch.cat([fft_result, padding], dim=1)
        
        # åˆ†ç¦»å®éƒ¨å’Œè™šéƒ¨
        real_part = fft_result.real
        imag_part = fft_result.imag
        
        # ç»„åˆç‰¹å¾
        fourier_features = torch.cat([real_part, imag_part], dim=1)  # (batch_size, num_freqs * 2)
        
        return fourier_features
        
    def extract_invariant_features(self, points):
        """
        æå–æ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ä¸å˜çš„ç‰¹å¾
        Args:
            points: (batch_size, num_points, 2)
        Returns:
            invariant_features: (batch_size, feature_dim)
        """
        batch_size, num_points, _ = points.shape
        
        # å½’ä¸€åŒ–åˆ°åŸç‚¹å’Œå•ä½å°ºåº¦
        centroid = torch.mean(points, dim=1, keepdim=True)
        centered_points = points - centroid
        
        # ç¼©æ”¾å½’ä¸€åŒ–
        distances = torch.norm(centered_points, dim=2)
        max_dist = torch.max(distances, dim=1, keepdim=True)[0]
        max_dist = torch.clamp(max_dist, min=1e-6)
        normalized_points = centered_points / max_dist.unsqueeze(-1)
        
        # å‚…é‡Œå¶æè¿°ç¬¦
        fourier_desc = self.extract_fourier_descriptors(normalized_points)
        
        # ä½¿å‚…é‡Œå¶æè¿°ç¬¦å…·æœ‰æ—‹è½¬ä¸å˜æ€§
        # æ–¹æ³•ï¼šä½¿ç”¨å¹…åº¦è°±è€Œéç›¸ä½
        real_part = fourier_desc[:, :self.num_freqs]
        imag_part = fourier_desc[:, self.num_freqs:]
        magnitude = torch.sqrt(real_part**2 + imag_part**2)
        
        # ä¿ç•™ä¸€äº›ç›¸ä½ä¿¡æ¯ï¼ˆç›¸å¯¹ç›¸ä½ï¼‰
        phase = torch.atan2(imag_part, real_part)
        relative_phase = phase[:, 1:] - phase[:, :-1]  # ç›¸å¯¹ç›¸ä½
        
        # ç»„åˆå¹…åº¦å’Œç›¸å¯¹ç›¸ä½
        combined_features = torch.cat([magnitude, relative_phase], dim=1)
        
        return combined_features
        
    def forward(self, points):
        """
        å‰å‘ä¼ æ’­
        Args:
            points: (batch_size, num_points, 2)
        Returns:
            shape_features: (batch_size, feature_dim)
        """
        # 1. å‚…é‡Œå¶ç‰¹å¾
        invariant_features = self.extract_invariant_features(points)
        fourier_features = self.fourier_net(invariant_features)
        
        # 2. ç©ºé—´ç‰¹å¾ï¼ˆä½œä¸ºè¡¥å……ï¼‰
        spatial_input = points.transpose(1, 2)  # (batch_size, 2, num_points)
        spatial_features = self.spatial_encoder(spatial_input).squeeze(-1)
        
        # 3. ç‰¹å¾èåˆ
        combined = torch.cat([fourier_features, spatial_features], dim=1)
        final_features = self.fusion(combined)
        
        return final_features

class FourierBasedMatchingNet(nn.Module):
    """
    åŸºäºå‚…é‡Œå¶å˜æ¢çš„ç¢ç‰‡åŒ¹é…ç½‘ç»œ
    """
    def __init__(self, max_points=1000, num_freqs=64, feature_dim=128):
        super().__init__()
        self.max_points = max_points
        self.feature_dim = feature_dim
        
        # å‚…é‡Œå¶å½¢çŠ¶ç¼–ç å™¨
        self.shape_encoder = FourierShapeEncoder(max_points, num_freqs, feature_dim)
        
        # å‡ ä½•ç‰¹å¾æå–å™¨
        self.geometry_extractor = nn.Sequential(
            nn.Linear(8, 64),  # å‡ ä½•ç‰¹å¾
            nn.ReLU(),
            nn.Linear(64, feature_dim // 4)
        )
        
        # ç‰¹å¾èåˆ
        self.feature_fusion = nn.Sequential(
            nn.Linear(feature_dim + feature_dim // 4, feature_dim),
            nn.ReLU(),
            nn.Dropout(0.2)
        )
        
        # åŒ¹é…ç½‘ç»œ
        self.matching_net = nn.Sequential(
            nn.Linear(feature_dim * 4 + 2, 256),  # feat1, feat2, diff, hadamard, cosine + L2
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        
    def extract_geometric_features(self, points):
        """
        æå–åŸºæœ¬å‡ ä½•ç‰¹å¾
        Args:
            points: (batch_size, num_points, 2)
        Returns:
            geo_features: (batch_size, 8)
        """
        batch_size = points.shape[0]
        features = []
        
        for b in range(batch_size):
            pts = points[b].cpu().numpy()
            
            # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
            centroid = np.mean(pts, axis=0)
            std = np.std(pts, axis=0)
            
            # è¾¹ç•Œæ¡†
            bbox_min = np.min(pts, axis=0)
            bbox_max = np.max(pts, axis=0)
            bbox_size = bbox_max - bbox_min
            
            # ç»„åˆç‰¹å¾
            geo_feat = np.concatenate([
                centroid,     # 2
                std,         # 2
                bbox_size,   # 2
                [np.mean(np.linalg.norm(pts - centroid, axis=1))],  # 1: å¹³å‡è·ç¦»
                [np.std(np.linalg.norm(pts - centroid, axis=1))]    # 1: è·ç¦»æ ‡å‡†å·®
            ])
            
            features.append(geo_feat)
        
        return torch.FloatTensor(features).to(points.device)
        
    def forward(self, points1, points2):
        """
        å‰å‘ä¼ æ’­
        Args:
            points1: (batch_size, num_points1, 2)
            points2: (batch_size, num_points2, 2)
        Returns:
            match_logits: (batch_size, 1)
        """
        # 1. å½¢çŠ¶ç‰¹å¾ç¼–ç 
        shape_feat1 = self.shape_encoder(points1)
        shape_feat2 = self.shape_encoder(points2)
        
        # 2. å‡ ä½•ç‰¹å¾æå–
        geo_feat1 = self.extract_geometric_features(points1)
        geo_feat2 = self.extract_geometric_features(points2)
        
        geo_encoded1 = self.geometry_extractor(geo_feat1)
        geo_encoded2 = self.geometry_extractor(geo_feat2)
        
        # 3. ç‰¹å¾èåˆ
        fused_feat1 = self.feature_fusion(torch.cat([shape_feat1, geo_encoded1], dim=1))
        fused_feat2 = self.feature_fusion(torch.cat([shape_feat2, geo_encoded2], dim=1))
        
        # 4. åŒ¹é…ç‰¹å¾è®¡ç®—
        diff = fused_feat1 - fused_feat2
        hadamard = fused_feat1 * fused_feat2
        
        # ç›¸ä¼¼åº¦åº¦é‡
        cosine_sim = F.cosine_similarity(fused_feat1, fused_feat2, dim=1, eps=1e-8)
        l2_dist = torch.norm(diff, p=2, dim=1)
        
        # 5. ç‰¹å¾ç»„åˆ
        combined = torch.cat([
            fused_feat1,
            fused_feat2, 
            diff,
            hadamard,
            cosine_sim.unsqueeze(1),
            l2_dist.unsqueeze(1)
        ], dim=1)
        
        # 6. åŒ¹é…é¢„æµ‹
        match_logits = self.matching_net(combined)
        
        return match_logits

class HybridFourierNet(nn.Module):
    """
    æ··åˆå‚…é‡Œå¶ç½‘ç»œï¼šç»“åˆå‚…é‡Œå¶å˜æ¢å’Œé«˜é‡‡æ ·æ–¹æ³•
    """
    def __init__(self, max_points=1000, num_freqs=64, feature_dim=128, num_samples=10):
        super().__init__()
        self.num_samples = num_samples
        
        # å‚…é‡Œå¶ç¼–ç å™¨
        self.fourier_encoder = FourierShapeEncoder(max_points, num_freqs, feature_dim)
        
        # å¤šå°ºåº¦é‡‡æ ·å™¨
        self.segment_lengths = [30, 50, 80]  # å¤šç§æ®µè½é•¿åº¦
        
        # åŒ¹é…ç½‘ç»œ
        self.matching_net = nn.Sequential(
            nn.Linear(feature_dim * 4 + 1, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )
        
        # ç»“æœèšåˆ
        self.aggregator = nn.Sequential(
            nn.Linear(len(self.segment_lengths), 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )
        
    def random_segment_sampling(self, points, segment_length, num_samples):
        """
        éšæœºæ®µè½é‡‡æ ·
        """
        batch_size, num_points, _ = points.shape
        
        if num_points < segment_length:
            return [points] * num_samples
            
        segments = []
        for _ in range(num_samples):
            start_indices = torch.randint(0, num_points - segment_length + 1, (batch_size,))
            
            segment_batch = []
            for b in range(batch_size):
                start_idx = start_indices[b].item()
                end_idx = start_idx + segment_length
                segment = points[b, start_idx:end_idx]
                segment_batch.append(segment)
            
            segments.append(torch.stack(segment_batch, dim=0))
        
        return segments
        
    def forward(self, points1, points2):
        """
        å‰å‘ä¼ æ’­
        """
        scale_results = []
        
        # å¯¹æ¯ç§å°ºåº¦è¿›è¡Œå¤„ç†
        for segment_length in self.segment_lengths:
            # é‡‡æ ·æ®µè½
            segments1 = self.random_segment_sampling(points1, segment_length, self.num_samples)
            segments2 = self.random_segment_sampling(points2, segment_length, self.num_samples)
            
            sample_scores = []
            
            # å¤„ç†æ¯ä¸ªé‡‡æ ·å¯¹
            for seg1, seg2 in zip(segments1, segments2):
                # å‚…é‡Œå¶ç¼–ç 
                feat1 = self.fourier_encoder(seg1)
                feat2 = self.fourier_encoder(seg2)
                
                # åŒ¹é…ç‰¹å¾
                diff = feat1 - feat2
                hadamard = feat1 * feat2
                cosine_sim = F.cosine_similarity(feat1, feat2, dim=1, eps=1e-8)
                
                combined = torch.cat([feat1, feat2, diff, hadamard, cosine_sim.unsqueeze(1)], dim=1)
                score = self.matching_net(combined)
                sample_scores.append(score)
            
            # å¹³å‡é‡‡æ ·ç»“æœ
            scale_score = torch.mean(torch.stack(sample_scores, dim=1), dim=1)
            scale_results.append(scale_score)
        
        # èšåˆå¤šå°ºåº¦ç»“æœ
        scale_features = torch.cat(scale_results, dim=1)
        final_logits = self.aggregator(scale_features)
        
        return final_logits

# æµ‹è¯•å‡½æ•°
def test_fourier_networks():
    """æµ‹è¯•å‚…é‡Œå¶å˜æ¢ç½‘ç»œ"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")
    
    # æµ‹è¯•åŸºç¡€å‚…é‡Œå¶ç½‘ç»œ
    print("ğŸ§ª æµ‹è¯•åŸºç¡€å‚…é‡Œå¶ç½‘ç»œ...")
    fourier_net = FourierBasedMatchingNet(
        max_points=1000, 
        num_freqs=64, 
        feature_dim=128
    ).to(device)
    
    # æµ‹è¯•æ··åˆå‚…é‡Œå¶ç½‘ç»œ
    print("ğŸ§ª æµ‹è¯•æ··åˆå‚…é‡Œå¶ç½‘ç»œ...")
    hybrid_net = HybridFourierNet(
        max_points=1000,
        num_freqs=64,
        feature_dim=128,
        num_samples=5
    ).to(device)
    
    # æµ‹è¯•æ•°æ®
    batch_size = 4
    points1 = torch.randn(batch_size, 800, 2).to(device)
    points2 = torch.randn(batch_size, 900, 2).to(device)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    with torch.no_grad():
        output1 = fourier_net(points1, points2)
        output2 = hybrid_net(points1, points2)
    
    print(f"åŸºç¡€å‚…é‡Œå¶ç½‘ç»œè¾“å‡º: {output1.shape}")
    print(f"åŸºç¡€å‚…é‡Œå¶ç½‘ç»œå‚æ•°: {sum(p.numel() for p in fourier_net.parameters()):,}")
    
    print(f"æ··åˆå‚…é‡Œå¶ç½‘ç»œè¾“å‡º: {output2.shape}")
    print(f"æ··åˆå‚…é‡Œå¶ç½‘ç»œå‚æ•°: {sum(p.numel() for p in hybrid_net.parameters()):,}")
    
    print("æµ‹è¯•æˆåŠŸ!")
    
    return fourier_net, hybrid_net

if __name__ == "__main__":
    test_fourier_networks()