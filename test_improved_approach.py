#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›æ–¹æ¡ˆ
ä¸“æ³¨äºç‰¹å¾å·¥ç¨‹è€Œéå¤šé‡‡æ ·
"""
import torch
import torch.nn as nn
import torch.optim as optim
import os
import time
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
import numpy as np

from hybrid_approach.improved_approach import ImprovedEdgeMatchingNet
# ä¸ºäº†å¯¹æ¯”ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªç®€å•çš„åŸºçº¿ç½‘ç»œ
class BaselineNet(nn.Module):
    def __init__(self, max_points=1000):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(2, 64),
            nn.ReLU(),
            nn.Linear(64, 128),
            nn.ReLU(),
            nn.Linear(128, 64)
        )
        self.classifier = nn.Sequential(
            nn.Linear(64 * 2 + 64 + 1, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )
        
    def forward(self, points1, points2):
        # å…¨å±€å¹³å‡æ± åŒ–
        feat1 = torch.mean(self.encoder(points1), dim=1)
        feat2 = torch.mean(self.encoder(points2), dim=1)
        
        diff = feat1 - feat2
        dot = torch.sum(feat1 * feat2, dim=1, keepdim=True)
        combined = torch.cat([feat1, feat2, diff, dot], dim=1)
        return self.classifier(combined)
from simplified_approach.dataset_simple import create_simple_dataloaders

def test_improved_approach():
    """æµ‹è¯•æ”¹è¿›æ–¹æ¡ˆ"""
    print("ğŸš€ æµ‹è¯•æ”¹è¿›æ–¹æ¡ˆ")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ“š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader, val_loader, test_loader = create_simple_dataloaders(
        "dataset/train_set.pkl",
        "dataset/valid_set.pkl",
        "dataset/test_set.pkl",
        batch_size=32,
        max_points=1000,
        num_workers=4
    )
    
    # æµ‹è¯•æ¨¡å‹
    models = [
        {
            'name': 'Simple Baseline',
            'model': BaselineNet(max_points=1000)
        },
        {
            'name': 'Improved Approach',
            'model': ImprovedEdgeMatchingNet(max_points=1000, feature_dim=128)
        }
    ]
    
    results = []
    
    for model_config in models:
        print(f"\nğŸ§ª æµ‹è¯•æ¨¡å‹: {model_config['name']}")
        print("=" * 40)
        
        model = model_config['model'].to(device)
        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
        criterion = nn.BCEWithLogitsLoss()
        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
        
        # è®­ç»ƒ
        epochs = 20
        best_acc = 0.0
        best_f1 = 0.0
        best_auc = 0.0
        training_time = 0.0
        
        for epoch in range(epochs):
            epoch_start = time.time()
            
            # è®­ç»ƒ
            model.train()
            train_loss = 0.0
            train_preds = []
            train_labels = []
            
            for batch_idx, batch in enumerate(train_loader):
                points1 = batch['source_points'].to(device)
                points2 = batch['target_points'].to(device)
                labels = batch['label'].to(device)
                
                optimizer.zero_grad()
                logits = model(points1, points2)
                loss = criterion(logits, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                train_preds.extend(preds.cpu().numpy())
                train_labels.extend(labels.cpu().numpy())
                
                if batch_idx % 50 == 0:
                    print(f'     Batch {batch_idx:3d}/{len(train_loader):3d} | Loss: {loss.item():.4f}')
            
            scheduler.step()
            
            train_acc = accuracy_score(train_labels, train_preds)
            train_loss /= len(train_loader)
            
            # éªŒè¯
            model.eval()
            val_loss = 0.0
            val_preds = []
            val_probs = []
            val_labels = []
            
            with torch.no_grad():
                for batch in val_loader:
                    points1 = batch['source_points'].to(device)
                    points2 = batch['target_points'].to(device)
                    labels = batch['label'].to(device)
                    
                    logits = model(points1, points2)
                    loss = criterion(logits, labels)
                    val_loss += loss.item()
                    
                    probs = torch.sigmoid(logits)
                    preds = (probs > 0.5).float()
                    val_preds.extend(preds.cpu().numpy())
                    val_probs.extend(probs.cpu().numpy())
                    val_labels.extend(labels.cpu().numpy())
            
            val_loss /= len(val_loader)
            val_acc = accuracy_score(val_labels, val_preds)
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡
            try:
                precision, recall, f1, _ = precision_recall_fscore_support(
                    val_labels, val_preds, average='binary', zero_division=0
                )
                auc = roc_auc_score(val_labels, val_probs)
            except:
                precision, recall, f1, auc = 0.0, 0.0, 0.0, 0.5
            
            # æ›´æ–°æœ€ä½³ç»“æœ
            if val_acc > best_acc:
                best_acc = val_acc
                best_f1 = f1
                best_auc = auc
            
            epoch_time = time.time() - epoch_start
            training_time += epoch_time
            
            print(f'   Epoch {epoch+1:2d}: Train={train_acc:.4f}, Val={val_acc:.4f}, '
                  f'F1={f1:.4f}, AUC={auc:.4f}, Time={epoch_time:.1f}s')
            
            # æå‰åœæ­¢
            if epoch - ([i for i, h in enumerate(results) if h['best_acc'] == best_acc] or [0])[-1] > 5:
                print(f'   Early stopping at epoch {epoch+1}')
                break
        
        results.append({
            'name': model_config['name'],
            'best_acc': best_acc,
            'best_f1': best_f1,
            'best_auc': best_auc,
            'training_time': training_time,
            'params': sum(p.numel() for p in model.parameters()),
            'avg_epoch_time': training_time / (epoch + 1)
        })
        
        print(f'   âœ… å®Œæˆ: æœ€ä½³å‡†ç¡®ç‡={best_acc:.4f}, æ€»è®­ç»ƒæ—¶é—´={training_time:.1f}s')
    
    # æ€»ç»“ç»“æœ
    print(f"\nğŸ“Š æ”¹è¿›æ–¹æ¡ˆæµ‹è¯•ç»“æœ")
    print("=" * 80)
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    results.sort(key=lambda x: x['best_acc'], reverse=True)
    
    print(f"{'æ’å':<4} {'æ–¹æ³•':<25} {'å‡†ç¡®ç‡':<8} {'F1':<8} {'AUC':<8} {'å‚æ•°é‡':<10} {'å¹³å‡æ—¶é—´':<10}")
    print("-" * 80)
    
    for i, result in enumerate(results):
        print(f"{i+1:<4} {result['name']:<25} {result['best_acc']:.4f}   {result['best_f1']:.4f}   "
              f"{result['best_auc']:.4f}   {result['params']:,}   {result['avg_epoch_time']:.1f}s")
    
    # è¯¦ç»†åˆ†æ
    print(f"\nğŸ“ˆ è¯¦ç»†åˆ†æ")
    print("=" * 50)
    
    if len(results) >= 2:
        baseline = results[1] if results[0]['name'] == 'Improved Approach' else results[0]
        improved = results[0] if results[0]['name'] == 'Improved Approach' else results[1]
        
        print(f"ğŸ† æœ€ä½³æ–¹æ³•: {results[0]['name']}")
        print(f"   å‡†ç¡®ç‡: {results[0]['best_acc']:.4f}")
        print(f"   F1-Score: {results[0]['best_f1']:.4f}")
        print(f"   AUC: {results[0]['best_auc']:.4f}")
        
        acc_diff = improved['best_acc'] - baseline['best_acc']
        f1_diff = improved['best_f1'] - baseline['best_f1']
        auc_diff = improved['best_auc'] - baseline['best_auc']
        time_diff = improved['avg_epoch_time'] - baseline['avg_epoch_time']
        
        print(f"\nğŸ“Š æ”¹è¿›æ–¹æ¡ˆ vs Baseline:")
        print(f"   å‡†ç¡®ç‡å·®å¼‚: {acc_diff:+.4f} ({acc_diff/baseline['best_acc']*100:+.1f}%)")
        print(f"   F1å·®å¼‚: {f1_diff:+.4f} ({f1_diff/baseline['best_f1']*100:+.1f}%)")
        print(f"   AUCå·®å¼‚: {auc_diff:+.4f} ({auc_diff/baseline['best_auc']*100:+.1f}%)")
        print(f"   è®­ç»ƒæ—¶é—´å·®å¼‚: {time_diff:+.1f}s/epoch")
        
        # ç»¼åˆè¯„ä¼°
        print(f"\nğŸ¯ ç»¼åˆè¯„ä¼°:")
        if acc_diff > 0.01:
            print("   âœ… å‡†ç¡®ç‡æ˜¾è‘—æå‡")
        elif acc_diff > 0.005:
            print("   âš ï¸ å‡†ç¡®ç‡å°å¹…æå‡")
        else:
            print("   âŒ å‡†ç¡®ç‡æ— æ˜æ˜¾æå‡")
        
        if time_diff < 5:
            print("   âœ… è®­ç»ƒæ—¶é—´å¼€é”€å¯æ¥å—")
        else:
            print("   âš ï¸ è®­ç»ƒæ—¶é—´å¼€é”€è¾ƒå¤§")
    
    # ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”
    print(f"\nğŸ“‹ ä¸å…¶ä»–æ–¹æ³•å¯¹æ¯”:")
    comparisons = [
        ('åŸå§‹å¤æ‚ç½‘ç»œ', 0.5000),
        ('ç®€åŒ–ç½‘ç»œ', 0.5985),
        ('final_approach', 0.6095),
        ('æ··åˆæ–¹æ³•(å•é‡‡æ ·)', 0.5839),
        ('æ”¹è¿›æ–¹æ¡ˆ', results[0]['best_acc'])
    ]
    
    for method, acc in comparisons:
        if method == 'æ”¹è¿›æ–¹æ¡ˆ':
            print(f"   ğŸ† {method}: {acc:.4f}")
        else:
            print(f"   ğŸ“Š {method}: {acc:.4f}")
    
    return results

if __name__ == "__main__":
    results = test_improved_approach()