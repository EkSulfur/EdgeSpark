#!/usr/bin/env python3
"""
å®Œæ•´çš„æ··åˆæ–¹æ³•æµ‹è¯•
"""
import torch
import torch.nn as nn
import torch.optim as optim
import os
import time
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
import numpy as np
import json
from datetime import datetime

from hybrid_approach.hybrid_network import HybridEdgeMatchingNet
from simplified_approach.dataset_simple import create_simple_dataloaders

def full_test_hybrid():
    """å®Œæ•´æµ‹è¯•æ··åˆæ–¹æ³•"""
    print("ğŸš€ æ··åˆæ–¹æ³•å®Œæ•´æµ‹è¯•")
    print("=" * 50)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ“š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader, val_loader, test_loader = create_simple_dataloaders(
        "dataset/train_set.pkl",
        "dataset/valid_set.pkl", 
        "dataset/test_set.pkl",
        batch_size=16,
        max_points=1000,
        num_workers=4
    )
    
    # æµ‹è¯•é…ç½®
    configs = [
        {
            'name': 'Baseline-å•æ¬¡é‡‡æ ·',
            'num_samples': 1,
            'sample_method': 'diversified',
            'ensemble_method': 'simple_average'
        },
        {
            'name': '3é‡‡æ ·-å¤šæ ·åŒ–-ç®€å•å¹³å‡',
            'num_samples': 3,
            'sample_method': 'diversified',
            'ensemble_method': 'simple_average'
        },
        {
            'name': '5é‡‡æ ·-å¤šæ ·åŒ–-åŠ æƒå¹³å‡',
            'num_samples': 5,
            'sample_method': 'diversified',
            'ensemble_method': 'weighted_average'
        },
        {
            'name': '3é‡‡æ ·-éšæœº-ç½®ä¿¡åº¦åŠ æƒ',
            'num_samples': 3,
            'sample_method': 'random',
            'ensemble_method': 'confidence_weighted'
        }
    ]
    
    results = []
    
    for config in configs:
        print(f"\nğŸ§ª æµ‹è¯•é…ç½®: {config['name']}")
        print(f"   é‡‡æ ·æ¬¡æ•°: {config['num_samples']}")
        
        # åˆ›å»ºæ¨¡å‹
        model = HybridEdgeMatchingNet(
            max_points=1000,
            num_samples=config['num_samples'],
            sample_method=config['sample_method'],
            ensemble_method=config['ensemble_method']
        ).to(device)
        
        # ä¼˜åŒ–å™¨
        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
        criterion = nn.BCEWithLogitsLoss()
        
        # è®­ç»ƒ
        epochs = 15
        best_acc = 0.0
        best_f1 = 0.0
        best_auc = 0.0
        training_time = 0.0
        
        for epoch in range(epochs):
            epoch_start = time.time()
            
            # è®­ç»ƒ
            model.train()
            train_loss = 0.0
            train_preds = []
            train_labels = []
            
            for batch_idx, batch in enumerate(train_loader):
                points1 = batch['source_points'].to(device)
                points2 = batch['target_points'].to(device)
                labels = batch['label'].to(device)
                
                optimizer.zero_grad()
                logits = model(points1, points2)
                loss = criterion(logits, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                train_preds.extend(preds.cpu().numpy())
                train_labels.extend(labels.cpu().numpy())
                
                if batch_idx % 50 == 0:
                    print(f'     Batch {batch_idx:3d}/{len(train_loader):3d} | Loss: {loss.item():.4f}')
            
            train_acc = accuracy_score(train_labels, train_preds)
            train_loss /= len(train_loader)
            
            # éªŒè¯
            model.eval()
            val_loss = 0.0
            val_preds = []
            val_probs = []
            val_labels = []
            
            with torch.no_grad():
                for batch in val_loader:
                    points1 = batch['source_points'].to(device)
                    points2 = batch['target_points'].to(device)
                    labels = batch['label'].to(device)
                    
                    logits = model(points1, points2)
                    loss = criterion(logits, labels)
                    val_loss += loss.item()
                    
                    probs = torch.sigmoid(logits)
                    preds = (probs > 0.5).float()
                    val_preds.extend(preds.cpu().numpy())
                    val_probs.extend(probs.cpu().numpy())
                    val_labels.extend(labels.cpu().numpy())
            
            val_loss /= len(val_loader)
            val_acc = accuracy_score(val_labels, val_preds)
            
            # è®¡ç®—å…¶ä»–æŒ‡æ ‡
            try:
                precision, recall, f1, _ = precision_recall_fscore_support(
                    val_labels, val_preds, average='binary', zero_division=0
                )
                auc = roc_auc_score(val_labels, val_probs)
            except:
                precision, recall, f1, auc = 0.0, 0.0, 0.0, 0.5
            
            # æ›´æ–°æœ€ä½³ç»“æœ
            if val_acc > best_acc:
                best_acc = val_acc
                best_f1 = f1
                best_auc = auc
            
            epoch_time = time.time() - epoch_start
            training_time += epoch_time
            
            print(f'   Epoch {epoch+1:2d}: Train={train_acc:.4f}, Val={val_acc:.4f}, '
                  f'F1={f1:.4f}, AUC={auc:.4f}, Time={epoch_time:.1f}s')
        
        results.append({
            'name': config['name'],
            'config': config,
            'best_acc': best_acc,
            'best_f1': best_f1,
            'best_auc': best_auc,
            'training_time': training_time,
            'params': sum(p.numel() for p in model.parameters())
        })
        
        print(f'   âœ… å®Œæˆ: æœ€ä½³å‡†ç¡®ç‡={best_acc:.4f}, è®­ç»ƒæ—¶é—´={training_time:.1f}s')
    
    # æ€»ç»“ç»“æœ
    print(f"\nğŸ“Š å®Œæ•´æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 80)
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    results.sort(key=lambda x: x['best_acc'], reverse=True)
    
    print(f"{'æ’å':<4} {'æ–¹æ³•':<20} {'å‡†ç¡®ç‡':<8} {'F1':<8} {'AUC':<8} {'è®­ç»ƒæ—¶é—´':<10} {'å‚æ•°é‡':<10}")
    print("-" * 80)
    
    for i, result in enumerate(results):
        print(f"{i+1:<4} {result['name']:<20} {result['best_acc']:.4f}   {result['best_f1']:.4f}   "
              f"{result['best_auc']:.4f}   {result['training_time']:.1f}s     {result['params']:,}")
    
    # åˆ†æç»“æœ
    print(f"\nğŸ“ˆ ç»“æœåˆ†æ")
    print("=" * 50)
    
    baseline_acc = 0.6095  # final_approachå‡†ç¡®ç‡
    best_result = results[0]
    
    print(f"ğŸ† æœ€ä½³æ–¹æ³•: {best_result['name']}")
    print(f"   å‡†ç¡®ç‡: {best_result['best_acc']:.4f}")
    print(f"   F1-Score: {best_result['best_f1']:.4f}")
    print(f"   AUC: {best_result['best_auc']:.4f}")
    print(f"   è®­ç»ƒæ—¶é—´: {best_result['training_time']:.1f}s")
    
    improvement = best_result['best_acc'] - baseline_acc
    print(f"\nğŸ“Š ä¸baseline (final_approach: {baseline_acc:.4f}) æ¯”è¾ƒ:")
    if improvement > 0:
        print(f"   âœ… æå‡: +{improvement:.4f} ({improvement/baseline_acc*100:.1f}%)")
    else:
        print(f"   âŒ ä¸‹é™: {improvement:.4f} ({improvement/baseline_acc*100:.1f}%)")
    
    # åˆ†æå¤šé‡‡æ ·çš„æ•ˆæœ
    single_sample = next((r for r in results if r['config']['num_samples'] == 1), None)
    multi_sample = [r for r in results if r['config']['num_samples'] > 1]
    
    if single_sample and multi_sample:
        print(f"\nğŸ” å¤šé‡‡æ ·æ•ˆæœåˆ†æ:")
        print(f"   å•æ¬¡é‡‡æ ·: {single_sample['best_acc']:.4f}")
        
        for result in multi_sample:
            samples = result['config']['num_samples']
            diff = result['best_acc'] - single_sample['best_acc']
            time_ratio = result['training_time'] / single_sample['training_time']
            
            print(f"   {samples}æ¬¡é‡‡æ ·: {result['best_acc']:.4f} "
                  f"({'+' if diff > 0 else ''}{diff:.4f}, "
                  f"{time_ratio:.1f}xæ—¶é—´)")
    
    # ä¿å­˜ç»“æœ
    save_path = f'hybrid_experiments/full_test_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    with open(save_path, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    return results

if __name__ == "__main__":
    results = full_test_hybrid()