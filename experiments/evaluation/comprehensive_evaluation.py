#!/usr/bin/env python3
"""
ç»¼åˆè¯„ä¼°è„šæœ¬
æµ‹è¯•æ‰€æœ‰æ”¹è¿›æ–¹æ¡ˆå¹¶å¯¹æ¯”ç»“æœ
"""
import torch
import torch.nn as nn
import torch.optim as optim
import time
import os
import sys
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score
import numpy as np
import json
from datetime import datetime

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥æ¨¡å—
sys.path.append('/home/eksulfur/EdgeSpark')

# å¯¼å…¥ç½‘ç»œ
from final_improvements.high_sampling_approach import HighSamplingEdgeMatchingNet
from final_improvements.fourier_approach import FourierBasedMatchingNet, HybridFourierNet
from simplified_approach.dataset_simple import create_simple_dataloaders

def quick_train_and_evaluate(model, model_name, train_loader, val_loader, device, epochs=10):
    """
    å¿«é€Ÿè®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹
    """
    print(f"\nğŸš€ è®­ç»ƒæ¨¡å‹: {model_name}")
    print("-" * 50)
    
    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
    criterion = nn.BCEWithLogitsLoss()
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.7)
    
    best_acc = 0.0
    best_f1 = 0.0
    best_auc = 0.0
    training_time = 0.0
    
    for epoch in range(epochs):
        epoch_start = time.time()
        
        # è®­ç»ƒ
        model.train()
        train_loss = 0.0
        train_preds = []
        train_labels = []
        
        for batch_idx, batch in enumerate(train_loader):
            if batch_idx >= 50:  # é™åˆ¶æ‰¹æ¬¡æ•°é‡ä»¥åŠ å¿«æµ‹è¯•
                break
                
            points1 = batch['source_points'].to(device)
            points2 = batch['target_points'].to(device)
            labels = batch['label'].to(device)
            
            optimizer.zero_grad()
            
            try:
                logits = model(points1, points2)
                loss = criterion(logits, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                train_loss += loss.item()
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                train_preds.extend(preds.cpu().numpy())
                train_labels.extend(labels.cpu().numpy())
                
            except Exception as e:
                print(f"   è®­ç»ƒé”™è¯¯: {e}")
                continue
        
        scheduler.step()
        
        if not train_preds:
            print(f"   Epoch {epoch+1}: è®­ç»ƒå¤±è´¥")
            continue
            
        train_acc = accuracy_score(train_labels, train_preds)
        train_loss /= min(50, len(train_loader))
        
        # éªŒè¯
        model.eval()
        val_preds = []
        val_probs = []
        val_labels = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                if batch_idx >= 20:  # é™åˆ¶éªŒè¯æ‰¹æ¬¡
                    break
                    
                points1 = batch['source_points'].to(device)
                points2 = batch['target_points'].to(device)
                labels = batch['label'].to(device)
                
                try:
                    logits = model(points1, points2)
                    probs = torch.sigmoid(logits)
                    preds = (probs > 0.5).float()
                    val_preds.extend(preds.cpu().numpy())
                    val_probs.extend(probs.cpu().numpy())
                    val_labels.extend(labels.cpu().numpy())
                except Exception as e:
                    print(f"   éªŒè¯é”™è¯¯: {e}")
                    continue
        
        if not val_preds:
            print(f"   Epoch {epoch+1}: éªŒè¯å¤±è´¥")
            continue
            
        val_acc = accuracy_score(val_labels, val_preds)
        
        # è®¡ç®—å…¶ä»–æŒ‡æ ‡
        try:
            precision, recall, f1, _ = precision_recall_fscore_support(
                val_labels, val_preds, average='binary', zero_division=0
            )
            auc = roc_auc_score(val_labels, val_probs)
        except:
            precision, recall, f1, auc = 0.0, 0.0, 0.0, 0.5
        
        # æ›´æ–°æœ€ä½³ç»“æœ
        if val_acc > best_acc:
            best_acc = val_acc
            best_f1 = f1
            best_auc = auc
        
        epoch_time = time.time() - epoch_start
        training_time += epoch_time
        
        print(f"   Epoch {epoch+1:2d}: Train={train_acc:.4f}, Val={val_acc:.4f}, "
              f"F1={f1:.4f}, AUC={auc:.4f}, Time={epoch_time:.1f}s")
    
    return {
        'model_name': model_name,
        'best_acc': best_acc,
        'best_f1': best_f1,
        'best_auc': best_auc,
        'training_time': training_time,
        'params': sum(p.numel() for p in model.parameters()),
        'avg_epoch_time': training_time / epochs
    }

def comprehensive_evaluation():
    """
    ç»¼åˆè¯„ä¼°æ‰€æœ‰æ”¹è¿›æ–¹æ¡ˆ
    """
    print("ğŸ¯ EdgeSpark ç»¼åˆæ”¹è¿›æ–¹æ¡ˆè¯„ä¼°")
    print("=" * 80)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“š å‡†å¤‡æ•°æ®...")
    try:
        train_loader, val_loader, test_loader = create_simple_dataloaders(
            "dataset/train_set.pkl",
            "dataset/valid_set.pkl",
            "dataset/test_set.pkl",
            batch_size=16,
            max_points=1000,
            num_workers=2
        )
        print(f"   è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}")
        print(f"   éªŒè¯æ ·æœ¬: {len(val_loader.dataset)}")
    except Exception as e:
        print(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # æµ‹è¯•æ¨¡å‹é…ç½®
    model_configs = [
        {
            'name': 'é«˜é‡‡æ ·æ–¹æ¡ˆ(10é‡‡æ ·)',
            'model_class': HighSamplingEdgeMatchingNet,
            'params': {'segment_length': 50, 'num_samples': 10, 'feature_dim': 128}
        },
        {
            'name': 'é«˜é‡‡æ ·æ–¹æ¡ˆ(20é‡‡æ ·)',
            'model_class': HighSamplingEdgeMatchingNet,
            'params': {'segment_length': 50, 'num_samples': 20, 'feature_dim': 128}
        },
        {
            'name': 'åŸºç¡€å‚…é‡Œå¶æ–¹æ¡ˆ',
            'model_class': FourierBasedMatchingNet,
            'params': {'max_points': 1000, 'num_freqs': 64, 'feature_dim': 128}
        },
        {
            'name': 'æ··åˆå‚…é‡Œå¶æ–¹æ¡ˆ',
            'model_class': HybridFourierNet,
            'params': {'max_points': 1000, 'num_freqs': 64, 'feature_dim': 128, 'num_samples': 5}
        }
    ]
    
    results = []
    
    for config in model_configs:
        print(f"\nğŸ§ª æµ‹è¯•: {config['name']}")
        print("=" * 60)
        
        try:
            # åˆ›å»ºæ¨¡å‹
            model = config['model_class'](**config['params']).to(device)
            print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
            
            # å¿«é€Ÿæµ‹è¯•å‰å‘ä¼ æ’­
            with torch.no_grad():
                test_batch = next(iter(val_loader))
                points1 = test_batch['source_points'][:2].to(device)
                points2 = test_batch['target_points'][:2].to(device)
                output = model(points1, points2)
                print(f"   å‰å‘ä¼ æ’­æµ‹è¯•: âœ… è¾“å‡ºå½¢çŠ¶ {output.shape}")
            
            # è®­ç»ƒå’Œè¯„ä¼°
            result = quick_train_and_evaluate(
                model, config['name'], train_loader, val_loader, device, epochs=8
            )
            results.append(result)
            
        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results.append({
                'model_name': config['name'],
                'best_acc': 0.0,
                'best_f1': 0.0,
                'best_auc': 0.0,
                'training_time': 0.0,
                'params': 0,
                'avg_epoch_time': 0.0,
                'error': str(e)
            })
    
    # æ€»ç»“ç»“æœ
    print(f"\nğŸ“Š ç»¼åˆè¯„ä¼°ç»“æœ")
    print("=" * 100)
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    valid_results = [r for r in results if r['best_acc'] > 0]
    valid_results.sort(key=lambda x: x['best_acc'], reverse=True)
    
    print(f"{'æ’å':<4} {'æ–¹æ³•':<25} {'å‡†ç¡®ç‡':<8} {'F1':<8} {'AUC':<8} {'å‚æ•°é‡':<10} {'å¹³å‡æ—¶é—´':<10}")
    print("-" * 100)
    
    for i, result in enumerate(valid_results):
        print(f"{i+1:<4} {result['model_name']:<25} {result['best_acc']:.4f}   "
              f"{result['best_f1']:.4f}   {result['best_auc']:.4f}   "
              f"{result['params']:,}   {result['avg_epoch_time']:.1f}s")
    
    # ä¸å·²çŸ¥åŸºå‡†å¯¹æ¯”
    print(f"\nğŸ“ˆ ä¸å·²çŸ¥åŸºå‡†å¯¹æ¯”")
    print("-" * 60)
    
    baselines = [
        ('åŸå§‹å¤æ‚ç½‘ç»œ', 0.5000),
        ('ç®€åŒ–ç½‘ç»œ', 0.5985),
        ('final_approach', 0.6095),
        ('æ··åˆæ–¹æ³•(å•é‡‡æ ·)', 0.5839),
        ('æ”¹è¿›æ–¹æ¡ˆ(ç‰¹å¾å·¥ç¨‹)', 0.6100)  # ä¼°è®¡å€¼
    ]
    
    print("æ–¹æ³•                          | å‡†ç¡®ç‡    | çŠ¶æ€")
    print("-" * 50)
    for method, acc in baselines:
        print(f"{method:<25} | {acc:.4f}   | å†å²ç»“æœ")
    
    if valid_results:
        best_new = valid_results[0]
        print(f"{best_new['model_name']:<25} | {best_new['best_acc']:.4f}   | ğŸ† æ–°æœ€ä½³")
        
        # åˆ†ææ”¹è¿›æ•ˆæœ
        best_baseline = 0.6095  # final_approach
        improvement = best_new['best_acc'] - best_baseline
        
        print(f"\nğŸ’¡ æ”¹è¿›åˆ†æ:")
        print(f"   æœ€ä½³æ–°æ–¹æ³•: {best_new['model_name']}")
        print(f"   å‡†ç¡®ç‡: {best_new['best_acc']:.4f}")
        print(f"   ä¸final_approachå¯¹æ¯”: {improvement:+.4f} ({improvement/best_baseline*100:+.1f}%)")
        
        if improvement > 0.01:
            print("   âœ… æ˜¾è‘—æ”¹è¿› - ç”¨æˆ·å»ºè®®æœ‰æ•ˆ")
        elif improvement > 0.005:
            print("   âš ï¸ å°å¹…æ”¹è¿› - æ–¹å‘æ­£ç¡®ï¼Œéœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
        else:
            print("   âŒ æ— æ˜æ˜¾æ”¹è¿› - éœ€è¦é‡æ–°æ€è€ƒç­–ç•¥")
    
    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f'final_improvements/evaluation_results_{timestamp}.json'
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    return results

if __name__ == "__main__":
    results = comprehensive_evaluation()