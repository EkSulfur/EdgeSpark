#!/usr/bin/env python3
"""
å¿«é€Ÿè¯„ä¼°æœ€ç»ˆæ”¹è¿›æ–¹æ¡ˆ
"""
import torch
import torch.nn as nn
import torch.optim as optim
import time
import sys
from sklearn.metrics import accuracy_score

# æ·»åŠ è·¯å¾„
sys.path.append('/home/eksulfur/EdgeSpark')

from final_improvements.high_sampling_approach import HighSamplingEdgeMatchingNet
from final_improvements.fourier_approach import FourierBasedMatchingNet, HybridFourierNet
from simplified_approach.dataset_simple import create_simple_dataloaders

def quick_evaluation():
    """å¿«é€Ÿè¯„ä¼°æ”¹è¿›æ–¹æ¡ˆ"""
    print("ğŸš€ EdgeSpark æœ€ç»ˆæ”¹è¿›æ–¹æ¡ˆå¿«é€Ÿè¯„ä¼°")
    print("=" * 60)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆå°æ‰¹é‡æµ‹è¯•ï¼‰
    print("\nğŸ“š å‡†å¤‡æ•°æ®...")
    try:
        train_loader, val_loader, test_loader = create_simple_dataloaders(
            "dataset/train_set.pkl",
            "dataset/valid_set.pkl",
            "dataset/test_set.pkl",
            batch_size=8,  # å°æ‰¹é‡
            max_points=500,  # è¾ƒå°‘ç‚¹æ•°
            num_workers=1
        )
        print(f"   æ•°æ®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"   æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return []
    
    # æµ‹è¯•é…ç½®
    models = [
        {
            'name': 'é«˜é‡‡æ ·æ–¹æ¡ˆ(5é‡‡æ ·)',
            'model': HighSamplingEdgeMatchingNet(segment_length=30, num_samples=5, feature_dim=64)
        },
        {
            'name': 'åŸºç¡€å‚…é‡Œå¶æ–¹æ¡ˆ',
            'model': FourierBasedMatchingNet(max_points=500, num_freqs=32, feature_dim=64)
        },
        {
            'name': 'æ··åˆå‚…é‡Œå¶æ–¹æ¡ˆ', 
            'model': HybridFourierNet(max_points=500, num_freqs=32, feature_dim=64, num_samples=3)
        }
    ]
    
    results = []
    
    for model_config in models:
        print(f"\nğŸ§ª æµ‹è¯•: {model_config['name']}")
        print("-" * 40)
        
        model = model_config['model'].to(device)
        optimizer = optim.Adam(model.parameters(), lr=0.002, weight_decay=1e-4)
        criterion = nn.BCEWithLogitsLoss()
        
        # å¿«é€Ÿè®­ç»ƒï¼ˆ5è½®ï¼‰
        best_acc = 0.0
        training_time = 0.0
        
        for epoch in range(5):
            epoch_start = time.time()
            
            # è®­ç»ƒ
            model.train()
            train_preds = []
            train_labels = []
            
            for batch_idx, batch in enumerate(train_loader):
                if batch_idx >= 20:  # é™åˆ¶æ‰¹æ¬¡
                    break
                    
                points1 = batch['source_points'].to(device)
                points2 = batch['target_points'].to(device)
                labels = batch['label'].to(device)
                
                optimizer.zero_grad()
                logits = model(points1, points2)
                loss = criterion(logits, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                train_preds.extend(preds.cpu().numpy())
                train_labels.extend(labels.cpu().numpy())
            
            train_acc = accuracy_score(train_labels, train_preds)
            
            # éªŒè¯
            model.eval()
            val_preds = []
            val_labels = []
            
            with torch.no_grad():
                for batch_idx, batch in enumerate(val_loader):
                    if batch_idx >= 10:  # é™åˆ¶éªŒè¯æ‰¹æ¬¡
                        break
                        
                    points1 = batch['source_points'].to(device)
                    points2 = batch['target_points'].to(device)
                    labels = batch['label'].to(device)
                    
                    logits = model(points1, points2)
                    probs = torch.sigmoid(logits)
                    preds = (probs > 0.5).float()
                    val_preds.extend(preds.cpu().numpy())
                    val_labels.extend(labels.cpu().numpy())
            
            val_acc = accuracy_score(val_labels, val_preds)
            
            if val_acc > best_acc:
                best_acc = val_acc
                
            epoch_time = time.time() - epoch_start
            training_time += epoch_time
            
            print(f"   Epoch {epoch+1}: Train={train_acc:.4f}, Val={val_acc:.4f}, Time={epoch_time:.1f}s")
        
        results.append({
            'name': model_config['name'],
            'best_acc': best_acc,
            'training_time': training_time,
            'params': sum(p.numel() for p in model.parameters())
        })
        
        print(f"   âœ… æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
    
    # æ€»ç»“ç»“æœ
    print(f"\nğŸ“Š å¿«é€Ÿè¯„ä¼°ç»“æœæ€»ç»“")
    print("=" * 60)
    
    results.sort(key=lambda x: x['best_acc'], reverse=True)
    
    print(f"{'æ’å':<4} {'æ–¹æ³•':<20} {'å‡†ç¡®ç‡':<8} {'å‚æ•°é‡':<10} {'è®­ç»ƒæ—¶é—´':<10}")
    print("-" * 60)
    
    for i, result in enumerate(results):
        print(f"{i+1:<4} {result['name']:<20} {result['best_acc']:.4f}   "
              f"{result['params']:,}   {result['training_time']:.1f}s")
    
    # ä¸å†å²åŸºå‡†å¯¹æ¯”
    print(f"\nğŸ“ˆ ä¸å†å²åŸºå‡†å¯¹æ¯”")
    print("-" * 40)
    
    baselines = [
        ('final_approach', 0.6095),
        ('æ··åˆæ–¹æ³•(å•é‡‡æ ·)', 0.5839),
        ('æ”¹è¿›æ–¹æ¡ˆ(ç‰¹å¾å·¥ç¨‹)', 0.6100)
    ]
    
    for method, acc in baselines:
        print(f"   {method}: {acc:.4f}")
    
    if results:
        best_result = results[0]
        print(f"   ğŸ† {best_result['name']}: {best_result['best_acc']:.4f}")
        
        baseline_acc = 0.6095
        improvement = best_result['best_acc'] - baseline_acc
        print(f"\nğŸ’¡ æ”¹è¿›åˆ†æ:")
        print(f"   ä¸final_approachå¯¹æ¯”: {improvement:+.4f} ({improvement/baseline_acc*100:+.1f}%)")
        
        if improvement > 0.02:
            print("   âœ… æ˜¾è‘—æ”¹è¿› - ç”¨æˆ·å»ºè®®éå¸¸æœ‰æ•ˆ!")
        elif improvement > 0.01:
            print("   âœ… æ˜æ˜¾æ”¹è¿› - ç”¨æˆ·å»ºè®®æœ‰æ•ˆ")
        elif improvement > 0.005:
            print("   âš ï¸ å°å¹…æ”¹è¿› - æ–¹å‘æ­£ç¡®") 
        else:
            print("   âŒ æ— æ˜æ˜¾æ”¹è¿› - éœ€è¦è¿›ä¸€æ­¥è°ƒä¼˜")
    
    return results

if __name__ == "__main__":
    results = quick_evaluation()