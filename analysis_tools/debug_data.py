"""
æ•°æ®è°ƒè¯•è„šæœ¬
åˆ†ææ•°æ®è´¨é‡å’Œåˆ†å¸ƒ
"""
import pickle
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import torch

def analyze_dataset(pkl_path):
    """åˆ†ææ•°æ®é›†"""
    print(f"\n=== åˆ†ææ•°æ®é›†: {pkl_path} ===")
    
    with open(pkl_path, 'rb') as f:
        data = pickle.load(f)
    
    edge_points = data['full_pcd_all']
    gt_pairs = data['GT_pairs']
    
    print(f"è¾¹ç¼˜ç‚¹äº‘æ•°é‡: {len(edge_points)}")
    print(f"åŒ¹é…å¯¹æ•°é‡: {len(gt_pairs)}")
    
    # åˆ†æç‚¹äº‘ç»Ÿè®¡
    point_counts = [len(points) for points in edge_points]
    print(f"ç‚¹æ•°ç»Ÿè®¡:")
    print(f"  æœ€å°: {min(point_counts)}")
    print(f"  æœ€å¤§: {max(point_counts)}")
    print(f"  å¹³å‡: {np.mean(point_counts):.1f}")
    print(f"  ä¸­ä½æ•°: {np.median(point_counts):.1f}")
    
    # æ£€æŸ¥ç©ºç‚¹äº‘
    empty_count = sum(1 for points in edge_points if len(points) == 0)
    print(f"ç©ºç‚¹äº‘æ•°é‡: {empty_count}")
    
    # åˆ†æè¾¹ç¼˜ç‚¹äº‘çš„ç©ºé—´åˆ†å¸ƒ
    all_points = []
    for points in edge_points:
        if len(points) > 0:
            all_points.extend(points)
    
    if all_points:
        all_points = np.array(all_points)
        print(f"å…¨å±€ç‚¹äº‘ç»Ÿè®¡:")
        print(f"  XèŒƒå›´: [{all_points[:, 0].min():.3f}, {all_points[:, 0].max():.3f}]")
        print(f"  YèŒƒå›´: [{all_points[:, 1].min():.3f}, {all_points[:, 1].max():.3f}]")
        print(f"  Xæ ‡å‡†å·®: {all_points[:, 0].std():.3f}")
        print(f"  Yæ ‡å‡†å·®: {all_points[:, 1].std():.3f}")
    
    # åˆ†æåŒ¹é…å¯¹
    print(f"\nåŒ¹é…å¯¹åˆ†æ:")
    source_indices = [pair[0] for pair in gt_pairs]
    target_indices = [pair[1] for pair in gt_pairs]
    
    print(f"æºç´¢å¼•èŒƒå›´: {min(source_indices)} - {max(source_indices)}")
    print(f"ç›®æ ‡ç´¢å¼•èŒƒå›´: {min(target_indices)} - {max(target_indices)}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„åŒ¹é…å¯¹
    unique_pairs = set(tuple(pair) for pair in gt_pairs)
    print(f"å”¯ä¸€åŒ¹é…å¯¹: {len(unique_pairs)}")
    print(f"é‡å¤åŒ¹é…å¯¹: {len(gt_pairs) - len(unique_pairs)}")
    
    return edge_points, gt_pairs

def compute_simple_features(edge_points):
    """è®¡ç®—ç®€å•çš„å‡ ä½•ç‰¹å¾"""
    features = []
    
    for points in edge_points:
        if len(points) == 0:
            features.append(np.zeros(8))
            continue
        
        points = np.array(points)
        
        # å‡ ä½•ç‰¹å¾
        centroid = np.mean(points, axis=0)
        bbox_min = np.min(points, axis=0)
        bbox_max = np.max(points, axis=0)
        bbox_size = bbox_max - bbox_min
        
        # ç»Ÿè®¡ç‰¹å¾
        std = np.std(points, axis=0)
        
        feature = np.concatenate([centroid, bbox_min, bbox_max, bbox_size, std])
        features.append(feature)
    
    return np.array(features)

def analyze_feature_separability(edge_points, gt_pairs):
    """åˆ†æç‰¹å¾çš„å¯åˆ†æ€§"""
    print(f"\n=== ç‰¹å¾å¯åˆ†æ€§åˆ†æ ===")
    
    # è®¡ç®—ç‰¹å¾
    features = compute_simple_features(edge_points)
    print(f"ç‰¹å¾ç»´åº¦: {features.shape}")
    
    # åˆ†ææ­£æ ·æœ¬å¯¹çš„ç‰¹å¾ç›¸ä¼¼æ€§
    positive_distances = []
    for pair in gt_pairs:
        source_idx, target_idx = pair[0], pair[1]
        if source_idx < len(features) and target_idx < len(features):
            feat1 = features[source_idx]
            feat2 = features[target_idx]
            dist = np.linalg.norm(feat1 - feat2)
            positive_distances.append(dist)
    
    # åˆ†æè´Ÿæ ·æœ¬å¯¹çš„ç‰¹å¾ç›¸ä¼¼æ€§
    negative_distances = []
    np.random.seed(42)
    for _ in range(len(gt_pairs)):
        idx1, idx2 = np.random.choice(len(features), 2, replace=False)
        pair_exists = any((p[0] == idx1 and p[1] == idx2) or (p[0] == idx2 and p[1] == idx1) for p in gt_pairs)
        if not pair_exists:
            feat1 = features[idx1]
            feat2 = features[idx2]
            dist = np.linalg.norm(feat1 - feat2)
            negative_distances.append(dist)
    
    print(f"æ­£æ ·æœ¬ç‰¹å¾è·ç¦»ç»Ÿè®¡:")
    print(f"  å¹³å‡: {np.mean(positive_distances):.4f}")
    print(f"  æ ‡å‡†å·®: {np.std(positive_distances):.4f}")
    print(f"  èŒƒå›´: [{np.min(positive_distances):.4f}, {np.max(positive_distances):.4f}]")
    
    print(f"è´Ÿæ ·æœ¬ç‰¹å¾è·ç¦»ç»Ÿè®¡:")
    print(f"  å¹³å‡: {np.mean(negative_distances):.4f}")
    print(f"  æ ‡å‡†å·®: {np.std(negative_distances):.4f}")
    print(f"  èŒƒå›´: [{np.min(negative_distances):.4f}, {np.max(negative_distances):.4f}]")
    
    # å¯åˆ†æ€§åˆ†æ
    pos_mean = np.mean(positive_distances)
    neg_mean = np.mean(negative_distances)
    
    print(f"\nå¯åˆ†æ€§åˆ†æ:")
    print(f"  æ­£æ ·æœ¬è·ç¦»æ›´å°: {pos_mean < neg_mean}")
    print(f"  è·ç¦»å·®: {abs(pos_mean - neg_mean):.4f}")
    
    # é‡å åˆ†æ
    pos_95 = np.percentile(positive_distances, 95)
    neg_5 = np.percentile(negative_distances, 5)
    
    print(f"  æ­£æ ·æœ¬95%åˆ†ä½æ•°: {pos_95:.4f}")
    print(f"  è´Ÿæ ·æœ¬5%åˆ†ä½æ•°: {neg_5:.4f}")
    print(f"  ç‰¹å¾é‡å : {pos_95 > neg_5}")
    
    return positive_distances, negative_distances

def test_simple_classifier(edge_points, gt_pairs):
    """æµ‹è¯•ç®€å•åˆ†ç±»å™¨"""
    print(f"\n=== ç®€å•åˆ†ç±»å™¨æµ‹è¯• ===")
    
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.metrics import accuracy_score, classification_report
    from sklearn.model_selection import train_test_split
    
    # å‡†å¤‡æ•°æ®
    features = compute_simple_features(edge_points)
    
    # åˆ›å»ºæ ·æœ¬
    X, y = [], []
    
    # æ­£æ ·æœ¬
    for pair in gt_pairs:
        source_idx, target_idx = pair[0], pair[1]
        if source_idx < len(features) and target_idx < len(features):
            feat1 = features[source_idx]
            feat2 = features[target_idx]
            combined_feat = np.concatenate([feat1, feat2, feat1 - feat2, feat1 * feat2])
            X.append(combined_feat)
            y.append(1)
    
    # è´Ÿæ ·æœ¬
    np.random.seed(42)
    for _ in range(len(gt_pairs)):
        idx1, idx2 = np.random.choice(len(features), 2, replace=False)
        pair_exists = any((p[0] == idx1 and p[1] == idx2) or (p[0] == idx2 and p[1] == idx1) for p in gt_pairs)
        if not pair_exists:
            feat1 = features[idx1]
            feat2 = features[idx2]
            combined_feat = np.concatenate([feat1, feat2, feat1 - feat2, feat1 * feat2])
            X.append(combined_feat)
            y.append(0)
    
    X = np.array(X)
    y = np.array(y)
    
    print(f"æ ·æœ¬æ•°é‡: {len(X)}")
    print(f"ç‰¹å¾ç»´åº¦: {X.shape[1]}")
    print(f"æ­£æ ·æœ¬æ¯”ä¾‹: {np.mean(y):.3f}")
    
    # è®­ç»ƒæµ‹è¯•åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # è®­ç»ƒéšæœºæ£®æ—
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)
    
    # è¯„ä¼°
    y_pred = rf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    
    print(f"éšæœºæ£®æ—å‡†ç¡®ç‡: {acc:.4f}")
    
    if acc > 0.6:
        print("âœ… ç‰¹å¾å…·æœ‰ä¸€å®šçš„åŒºåˆ†èƒ½åŠ›")
    else:
        print("âŒ ç‰¹å¾åŒºåˆ†èƒ½åŠ›è¾ƒå·®")
    
    return acc

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” EdgeSparkæ•°æ®è°ƒè¯•åˆ†æ")
    print("=" * 60)
    
    # åˆ†æè®­ç»ƒé›†
    train_edge_points, train_gt_pairs = analyze_dataset("dataset/train_set.pkl")
    
    # åˆ†æéªŒè¯é›†
    val_edge_points, val_gt_pairs = analyze_dataset("dataset/valid_set.pkl")
    
    # ç‰¹å¾å¯åˆ†æ€§åˆ†æ
    pos_dist, neg_dist = analyze_feature_separability(train_edge_points, train_gt_pairs)
    
    # ç®€å•åˆ†ç±»å™¨æµ‹è¯•
    acc = test_simple_classifier(train_edge_points, train_gt_pairs)
    
    print(f"\n=== æ€»ç»“ ===")
    if acc > 0.7:
        print("ğŸ‰ æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹åº”è¯¥èƒ½å¤Ÿå­¦ä¹ ")
        print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥ç½‘ç»œæ¶æ„å’Œè®­ç»ƒç­–ç•¥")
    elif acc > 0.6:
        print("âš ï¸  æ•°æ®è´¨é‡ä¸€èˆ¬ï¼Œå¯èƒ½éœ€è¦æ›´å¤æ‚çš„ç‰¹å¾")
        print("ğŸ’¡ å»ºè®®ï¼šå°è¯•æ›´æ·±çš„ç½‘ç»œæˆ–æ›´å¥½çš„ç‰¹å¾å·¥ç¨‹")
    else:
        print("ğŸ”´ æ•°æ®è´¨é‡è¾ƒå·®ï¼ŒåŸºæœ¬å‡ ä½•ç‰¹å¾æ— æ³•åŒºåˆ†")
        print("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥æ•°æ®è´¨é‡æˆ–å¯»æ‰¾æ›´å¥½çš„ç‰¹å¾è¡¨ç¤º")

if __name__ == "__main__":
    main()