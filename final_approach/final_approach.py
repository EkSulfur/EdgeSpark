"""
æœ€ç»ˆæ–¹æ³•ï¼šåŸºäºè¾¹ç¼˜å½¢çŠ¶ç‰¹å¾çš„ç½‘ç»œ
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import time
import json
from datetime import datetime
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score

from dataset_simple import create_simple_dataloaders

class EdgeShapeEncoder(nn.Module):
    """
    è¾¹ç¼˜å½¢çŠ¶ç¼–ç å™¨
    ä¸“é—¨è®¾è®¡ç”¨äºæ•æ‰è¾¹ç¼˜å½¢çŠ¶ç‰¹å¾
    """
    def __init__(self, max_points=1000):
        super().__init__()
        self.max_points = max_points
        
        # 1. å±€éƒ¨å½¢çŠ¶ç‰¹å¾æå–
        self.local_conv = nn.Sequential(
            nn.Conv1d(2, 64, kernel_size=9, padding=4),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Conv1d(64, 128, kernel_size=7, padding=3),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.Conv1d(128, 256, kernel_size=5, padding=2),
            nn.BatchNorm1d(256),
            nn.ReLU(),
        )
        
        # 2. å…¨å±€å½¢çŠ¶ç‰¹å¾æå–
        self.global_conv = nn.Sequential(
            nn.Conv1d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Conv1d(512, 256, kernel_size=3, padding=1),
            nn.BatchNorm1d(256),
            nn.ReLU(),
        )
        
        # 3. è‡ªé€‚åº”æ± åŒ–
        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)
        
        # 4. æœ€ç»ˆæŠ•å½±
        self.final_proj = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64)
        )
        
    def forward(self, points):
        """
        ç¼–ç è¾¹ç¼˜å½¢çŠ¶
        Args:
            points: (batch_size, num_points, 2)
        Returns:
            features: (batch_size, 64)
        """
        # è½¬æ¢ç»´åº¦
        x = points.transpose(1, 2)  # (batch_size, 2, num_points)
        
        # å±€éƒ¨ç‰¹å¾æå–
        local_features = self.local_conv(x)  # (batch_size, 256, num_points)
        
        # å…¨å±€ç‰¹å¾æå–
        global_features = self.global_conv(local_features)  # (batch_size, 256, num_points)
        
        # è‡ªé€‚åº”æ± åŒ–
        pooled = self.adaptive_pool(global_features).squeeze(-1)  # (batch_size, 256)
        
        # æœ€ç»ˆæŠ•å½±
        final_features = self.final_proj(pooled)  # (batch_size, 64)
        
        return final_features

class EdgeMatchingNet(nn.Module):
    """
    è¾¹ç¼˜åŒ¹é…ç½‘ç»œ
    """
    def __init__(self, max_points=1000):
        super().__init__()
        self.max_points = max_points
        
        # å½¢çŠ¶ç¼–ç å™¨
        self.shape_encoder = EdgeShapeEncoder(max_points)
        
        # åŒ¹é…ç½‘ç»œ
        self.matching_net = nn.Sequential(
            # è¾“å…¥ï¼šä¸¤ä¸ª64ç»´ç‰¹å¾æ‹¼æ¥ + å·®å€¼ + ç‚¹ç§¯
            nn.Linear(64 * 2 + 64 + 1, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 1)
        )
        
    def forward(self, points1, points2):
        """
        å‰å‘ä¼ æ’­
        Args:
            points1: (batch_size, num_points1, 2)
            points2: (batch_size, num_points2, 2)
        Returns:
            match_logits: (batch_size, 1)
        """
        # å½¢çŠ¶ç¼–ç 
        shape1 = self.shape_encoder(points1)  # (batch_size, 64)
        shape2 = self.shape_encoder(points2)  # (batch_size, 64)
        
        # ç‰¹å¾ç»„åˆ
        diff = shape1 - shape2  # å·®å€¼ç‰¹å¾
        dot = torch.sum(shape1 * shape2, dim=1, keepdim=True)  # ç‚¹ç§¯ç›¸ä¼¼åº¦
        
        # æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        combined = torch.cat([shape1, shape2, diff, dot], dim=1)  # (batch_size, 64*2+64+1)
        
        # åŒ¹é…é¢„æµ‹
        match_logits = self.matching_net(combined)
        
        return match_logits

class FinalTrainer:
    """æœ€ç»ˆè®­ç»ƒå™¨"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆ›å»ºæ¨¡å‹
        self.model = EdgeMatchingNet(max_points=1000).to(self.device)
        
        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001, weight_decay=1e-4)
        
        # å­¦ä¹ ç‡è°ƒåº¦
        self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimizer, step_size=15, gamma=0.5)
        
        # æŸå¤±å‡½æ•°
        self.criterion = nn.BCEWithLogitsLoss()
        
        # å†å²è®°å½•
        self.history = []
        
    def train_epoch(self, loader):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        all_preds = []
        all_labels = []
        
        for batch_idx, batch in enumerate(loader):
            points1 = batch['source_points'].to(self.device)
            points2 = batch['target_points'].to(self.device)
            labels = batch['label'].to(self.device)
            
            self.optimizer.zero_grad()
            
            # å‰å‘ä¼ æ’­
            logits = self.model(points1, points2)
            loss = self.criterion(logits, labels)
            
            # åå‘ä¼ æ’­
            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            probs = torch.sigmoid(logits)
            preds = (probs > 0.5).float()
            
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
            
            if batch_idx % 20 == 0:
                print(f'    Batch {batch_idx:3d}/{len(loader):3d} | Loss: {loss.item():.4f}')
        
        avg_loss = total_loss / len(loader)
        acc = accuracy_score(all_labels, all_preds)
        
        return avg_loss, acc
    
    def validate_epoch(self, loader):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        all_preds = []
        all_probs = []
        all_labels = []
        
        with torch.no_grad():
            for batch in loader:
                points1 = batch['source_points'].to(self.device)
                points2 = batch['target_points'].to(self.device)
                labels = batch['label'].to(self.device)
                
                logits = self.model(points1, points2)
                loss = self.criterion(logits, labels)
                
                total_loss += loss.item()
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).float()
                
                all_preds.extend(preds.cpu().numpy())
                all_probs.extend(probs.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        avg_loss = total_loss / len(loader)
        acc = accuracy_score(all_labels, all_preds)
        
        try:
            precision, recall, f1, _ = precision_recall_fscore_support(
                all_labels, all_preds, average='binary', zero_division=0
            )
            auc = roc_auc_score(all_labels, all_probs)
        except:
            precision, recall, f1, auc = 0.0, 0.0, 0.0, 0.5
        
        return avg_loss, acc, precision, recall, f1, auc
    
    def train(self, train_loader, val_loader, epochs=30):
        """è®­ç»ƒå¾ªç¯"""
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒæœ€ç»ˆç‰ˆæœ¬")
        print(f"æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
        
        best_acc = 0.0
        
        for epoch in range(epochs):
            print(f"\nğŸ“Š Epoch {epoch+1}/{epochs}")
            
            # è®­ç»ƒ
            train_loss, train_acc = self.train_epoch(train_loader)
            
            # éªŒè¯
            val_loss, val_acc, val_precision, val_recall, val_f1, val_auc = self.validate_epoch(val_loader)
            
            # å­¦ä¹ ç‡æ›´æ–°
            self.scheduler.step()
            
            # è®°å½•
            self.history.append({
                'epoch': epoch + 1,
                'train_loss': train_loss,
                'train_acc': train_acc,
                'val_loss': val_loss,
                'val_acc': val_acc,
                'val_f1': val_f1,
                'val_auc': val_auc,
                'lr': self.optimizer.param_groups[0]['lr']
            })
            
            # æ˜¾ç¤ºç»“æœ
            print(f"ğŸ“ˆ è®­ç»ƒ: Loss={train_loss:.4f}, Acc={train_acc:.4f}")
            print(f"ğŸ“Š éªŒè¯: Loss={val_loss:.4f}, Acc={val_acc:.4f}, F1={val_f1:.4f}, AUC={val_auc:.4f}")
            print(f"ğŸ“š å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_acc:
                best_acc = val_acc
                print(f"  ğŸ’¾ æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
                
                # ä¿å­˜æ¨¡å‹
                torch.save(self.model.state_dict(), 'best_final_model.pth')
            
            # æå‰åœæ­¢æ£€æŸ¥
            if epoch >= 10 and val_acc < 0.52:
                print("ğŸ”´ éªŒè¯å‡†ç¡®ç‡è¿‡ä½ï¼Œæå‰åœæ­¢")
                break
        
        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æœ€ä½³å‡†ç¡®ç‡: {best_acc:.4f}")
        return best_acc

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¥ EdgeSparkæœ€ç»ˆå°è¯•")
    print("=" * 50)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("ğŸ“š åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    train_loader, val_loader, test_loader = create_simple_dataloaders(
        "dataset/train_set.pkl",
        "dataset/valid_set.pkl",
        "dataset/test_set.pkl",
        batch_size=32,
        max_points=1000,
        num_workers=4
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = FinalTrainer()
    
    # å¼€å§‹è®­ç»ƒ
    best_acc = trainer.train(train_loader, val_loader, epochs=25)
    
    # ç»“æœåˆ†æ
    print(f"\n=== æœ€ç»ˆç»“æœ ===")
    if best_acc > 0.7:
        print("ğŸ‰ æˆåŠŸï¼æ¨¡å‹å­¦åˆ°äº†æœ‰ç”¨çš„ç‰¹å¾")
    elif best_acc > 0.6:
        print("âš ï¸  éƒ¨åˆ†æˆåŠŸï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    else:
        print("âŒ å¤±è´¥ï¼Œå¯èƒ½éœ€è¦é‡æ–°æ€è€ƒé—®é¢˜")
        print("ğŸ’¡ å»ºè®®ï¼š")
        print("   1. æ£€æŸ¥æ•°æ®é¢„å¤„ç†")
        print("   2. å°è¯•ä¸åŒçš„ç‰¹å¾è¡¨ç¤º")
        print("   3. è€ƒè™‘ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹")
        print("   4. å¢åŠ æ•°æ®å¢å¼º")
        print("   5. å°è¯•é›†æˆå­¦ä¹ ")
    
    return best_acc

if __name__ == "__main__":
    result = main()